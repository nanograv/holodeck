{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ae2ca1",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d760994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../init.ipy\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Builtin packages\n",
    "from importlib import reload\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# standard secondary packages\n",
    "import astropy as ap\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "# development packages\n",
    "import kalepy as kale\n",
    "import kalepy.utils\n",
    "import kalepy.plot\n",
    "\n",
    "# --- Holodeck ----\n",
    "import holodeck as holo\n",
    "import holodeck.sam\n",
    "from holodeck import cosmo, utils, plot\n",
    "from holodeck.constants import MSOL, PC, YR, MPC, GYR\n",
    "\n",
    "# Silence annoying numpy errors\n",
    "np.seterr(divide='ignore', invalid='ignore', over='ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Plotting settings\n",
    "mpl.rc('font', **{'family': 'serif', 'sans-serif': ['Times'], 'size': 15})\n",
    "mpl.rc('lines', solid_capstyle='round')\n",
    "mpl.rc('mathtext', fontset='cm')\n",
    "mpl.style.use('default')   # avoid dark backgrounds from dark theme vscode\n",
    "plt.rcParams.update({'grid.alpha': 0.5})\n",
    "\n",
    "# Load log and set logging level\n",
    "log = holo.log\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f78a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figax(fobs=None, plamp=1.0e-15, **kwargs):\n",
    "    plt.close('all')\n",
    "    fig, axes = plot.figax(**kwargs)\n",
    "\n",
    "    if plamp is not None:\n",
    "        if fobs is None:\n",
    "            xx = [0.05, 10.0]\n",
    "        else:\n",
    "            xx = utils.minmax(fobs) * YR\n",
    "\n",
    "        yy = plamp * np.power(xx, -2/3)\n",
    "        for ax in np.atleast_1d(axes):\n",
    "            ax.plot(xx, yy, 'k--', alpha=0.25)\n",
    "\n",
    "    return fig, axes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# path = (\n",
    "#     \"/Users/lzkelley/programs/nanograv/holodeck/output/test_2022-06-27/\"\n",
    "# )\n",
    "\n",
    "# path = Path(path)\n",
    "# files = list(path.glob(\"*.npz\"))\n",
    "# print(f\"Found {len(files)} files\")\n",
    "# pat = r'_p[0-9]{3}_r[0-9]{3}'\n",
    "\n",
    "# for ff in tqdm.tqdm(files):\n",
    "#     mat = re.search(pat, str(ff))\n",
    "#     if mat is None:\n",
    "#         continue\n",
    "#     mat = [mm for mm in mat.group().split('_') if len(mm.strip()) > 0]\n",
    "#     pp, rr = [mm[1:] for mm in mat]\n",
    "#     fname_new = f\"lib_sams__p{int(pp):06d}_r{int(rr):03d}.npz\"\n",
    "#     fname_new = path / fname_new\n",
    "#     fname_old = path / ff\n",
    "#     # print(f\"\\t{fname_old} ==> {fname_new}\")\n",
    "#     fname_old.rename(fname_new)\n",
    "#     if not fname_new.is_file():\n",
    "#         raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a00d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax()\n",
    "\n",
    "ax.plot(*plot._get_hist_steps(data['fobs'], data['gwb']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e44cf8",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e931cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_output_files(path_output, fname_merged):\n",
    "    re_pattern = \"sam_output_p([0-9]{3})_r([0-9]{3}).npz\"\n",
    "\n",
    "    path_output = os.path.abspath(path_output)\n",
    "    print(f\"{path_output=}\")\n",
    "    file_pattern = os.path.join(path_output, \"*.*\")\n",
    "    # files = sorted(glob.glob(file_pattern))\n",
    "    files = glob.glob(file_pattern)\n",
    "    num_files = len(files)\n",
    "    if num_files == 0:\n",
    "        raise RuntimeError(f\"No files found in '{path_output}'!\")\n",
    "\n",
    "    print(f\"Found {num_files=}, {files[0]=}\")\n",
    "    files = [ff for ff in files if re.search(re_pattern, ff) is not None]\n",
    "    num_files = len(files)\n",
    "    if num_files == 0:\n",
    "        raise RuntimeError(f\"No files matching pattern '{re_pattern}'!\")\n",
    "\n",
    "    print(f\"Found {num_files=} matching target pattern\")\n",
    "\n",
    "    data = np.load(files[0])\n",
    "    fobs = data['fobs']\n",
    "\n",
    "    num_pars = 10\n",
    "    num_reals = 300\n",
    "    gwf = np.zeros((num_pars, num_reals, fobs.size - 1))\n",
    "    gff = np.zeros_like(gwf)\n",
    "    gwb = np.zeros_like(gwf)\n",
    "    mmbulge_norm = np.ones(num_pars) * np.nan\n",
    "\n",
    "    if num_files != num_pars * num_reals:\n",
    "        err = f\"Found number of files '{num_files}' does not match {num_pars=} * {num_reals=} = {num_pars*num_reals}!\"\n",
    "        log.error(err)\n",
    "        raise ValueError(err)\n",
    "\n",
    "    for fil in tqdm.tqdm(files):\n",
    "        groups = re.findall(re_pattern, fil)[0]\n",
    "        pp, rr = [int(gg) for gg in groups]\n",
    "        # print(fil, \"===>\", pp, rr)\n",
    "        data = np.load(fil)\n",
    "\n",
    "        assert np.all(fobs == data['fobs'])\n",
    "        if np.isnan(mmbulge_norm[pp]):\n",
    "            mmbulge_norm[pp] = data['mmbulge_norm']\n",
    "            assert not np.isnan(mmbulge_norm[pp])\n",
    "        else:\n",
    "            assert mmbulge_norm[pp] == data['mmbulge_norm']\n",
    "\n",
    "        gff[pp, rr, :] = data['gff']\n",
    "        gwf[pp, rr, :] = data['gwf']\n",
    "        gwb[pp, rr, :] = data['gwb']\n",
    "\n",
    "    with h5py.File(fname_merged, 'w') as h5:\n",
    "        h5.create_dataset('fobs', data=fobs)\n",
    "        h5.create_dataset('gff', data=gff)\n",
    "        h5.create_dataset('gwf', data=gwf)\n",
    "        h5.create_dataset('gwb', data=gwb)\n",
    "        h5.create_dataset('mmbulge_norm', data=mmbulge_norm)\n",
    "        h5.attrs['num_pars'] = num_pars\n",
    "        h5.attrs['num_reals'] = num_reals\n",
    "\n",
    "    print(f\"Saved to '{fname_merged}' size {utils.get_file_size(fname_merged)}\")\n",
    "\n",
    "    return\n",
    "\n",
    "path_output = \"/Users/lzkelley/research/nanograv/holodeck/output\"\n",
    "fname_data = os.path.join(path_output, \"data.hdf5\")\n",
    "if not os.path.exists(fname_data):\n",
    "    merge_output_files(path_output, fname_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e933b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname_data, 'r') as h5:\n",
    "    fobs = h5['fobs'][()]\n",
    "    print(f\"{fobs.size} frequencies, {h5.attrs['num_reals']} realizations, {h5.attrs['num_pars']} parameters\")\n",
    "    gff = h5['gff'][()]\n",
    "    gwf = h5['gwf'][()]\n",
    "    gwb = h5['gwb'][()]\n",
    "    mmbulge_norm = h5['mmbulge_norm'][()]\n",
    "\n",
    "print(f\"{fobs.shape=}, {gwf.shape=}, {mmbulge_norm.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c91f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(mmbulge_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2980ddaa",
   "metadata": {},
   "source": [
    "## Quick Look at Data Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675f0e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gff.shape, gwf.shape, gwb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d408a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sampled_gwb(ax, fobs, gff, gwf, gwb):\n",
    "    xx = kale.utils.midpoints(fobs) * YR   # [1/sec] ==> [1/yr]\n",
    "    col, = ax.plot(xx, gwb, ls='-', alpha=0.75, lw=0.75)\n",
    "    col = col.get_color()\n",
    "\n",
    "    idx = (gwf > gwb)\n",
    "    xx = gff * YR   # [1/sec] ==> [1/yr]\n",
    "    ax.scatter(xx[idx], gwf[idx], color=col, s=10, alpha=0.5)\n",
    "    ax.scatter(xx[~idx], gwf[~idx], edgecolor=col, facecolor='none', s=10, alpha=0.5)\n",
    "    return\n",
    "\n",
    "fig, ax = figax()\n",
    "\n",
    "PAR = 5\n",
    "REAL = 0\n",
    "draw_sampled_gwb(ax, fobs, gff[PAR, REAL, :], gwf[PAR, REAL, :], gwb[PAR, REAL, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figax()\n",
    "xx = kale.utils.midpoints(fobs) * YR   # [1/sec] ==> [1/yr]\n",
    "\n",
    "PAR = 6\n",
    "for gw, lab in zip([gwf, gwb], ['fore', 'back']):\n",
    "    med, *span = np.percentile(gw[PAR, :, :], [50, 25, 75], axis=0)\n",
    "    col, = ax.plot(xx, med, label=lab)\n",
    "    col = col.get_color()\n",
    "    ax.fill_between(xx, *span, color=col, alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pars = gwb.shape[0]\n",
    "print(f\"{num_pars=}\")\n",
    "\n",
    "fig, axes = figax(figsize=[16, 6], ncols=2)\n",
    "xx = kale.utils.midpoints(fobs) * YR   # [1/sec] ==> [1/yr]\n",
    "\n",
    "for ax, gw, lab in zip(axes, [gwf, gwb], ['fore', 'back']):\n",
    "    ax.set_title(lab)\n",
    "    for pp in range(num_pars):\n",
    "        med, *span = np.percentile(gw[pp, :, :], [50, 25, 75], axis=0)\n",
    "        col, = ax.plot(xx, med, label=lab)\n",
    "        col = col.get_color()\n",
    "        ax.fill_between(xx, *span, color=col, alpha=0.5)\n",
    "\n",
    "# plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b23322",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = np.linspace(-17.5, -10, 300)\n",
    "xb = np.linspace(-16, -13, 300)\n",
    "fig, axes = figax(ncols=2, plamp=None, scale='lin')\n",
    "\n",
    "off = 0.2e15\n",
    "colors = [mpl.cm.get_cmap('RdBu')(ii) for ii in np.linspace(0.1, 0.9, num_pars)]\n",
    "\n",
    "FREQ = 0\n",
    "for ax, xx, gw, lab in zip(axes, [xf, xb], [gwf, gwb], ['fore', 'back']):\n",
    "    ax.set_title(lab)\n",
    "    for pp in range(num_pars):\n",
    "        zz = np.log10(gw[pp, :, FREQ])\n",
    "        _, yy = kale.density(zz, xx, probability=True)\n",
    "        col, = ax.plot(xx, yy, color=colors[pp])\n",
    "        col = col.get_color()\n",
    "        kale.carpet(zz, ax=ax, color=col)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ = 100\n",
    "\n",
    "xf = np.linspace(-18, -13.5, 300)\n",
    "xb = np.linspace(-18, -14.5, 300)\n",
    "fig, axes = figax(ncols=2, plamp=None, scale='lin')\n",
    "\n",
    "off = 0.2e15\n",
    "colors = [mpl.cm.get_cmap('RdBu')(ii) for ii in np.linspace(0.1, 0.9, num_pars)]\n",
    "\n",
    "for ax, xx, gw, lab in zip(axes, [xf, xb], [gwf, gwb], ['fore', 'back']):\n",
    "    ax.set_title(lab)\n",
    "    for pp in range(num_pars)[::-1]:\n",
    "        zz = np.log10(gw[pp, :, FREQ])\n",
    "        zz = zz[np.isfinite(zz)]\n",
    "        _, yy = kale.density(zz, xx, probability=True)\n",
    "        col, = ax.plot(xx, yy, color=colors[pp])\n",
    "        col = col.get_color()\n",
    "        kale.carpet(zz, ax=ax, color=col)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca937a8",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.signal as ssig\n",
    "import scipy.signal\n",
    "# import scipy.interpolate as interp\n",
    "\n",
    "# import scipy.linalg as sl\n",
    "# import scipy.special as ss\n",
    "# import scipy.constants as sc\n",
    "# import scipy.misc as scmisc\n",
    "# import scipy.integrate as si\n",
    "\n",
    "import george\n",
    "import george.kernels as kernels\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc52f2f",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d49e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE - Only need to train GP on number of frequencies in PTA analysis !\n",
    "NFREQ = 3\n",
    "\n",
    "freqs = kale.utils.midpoints(fobs[:NFREQ+1]) * YR\n",
    "\n",
    "# (P, R, F)\n",
    "gwb_spectra = gwb[:, :, :NFREQ] ** 2\n",
    "print(utils.stats(gwb_spectra))\n",
    "\n",
    "# Find all of the zeros and set them to be h_c = 1e-20\n",
    "# low_ind = np.where(gwb_spectra < 1e-40)\n",
    "# gwb_spectra[low_ind] = 1e-40\n",
    "\n",
    "# Find std over realizations\n",
    "# (P[arams], F[reqs])\n",
    "err = np.std(np.log10(gwb_spectra), axis=1)\n",
    "# Find mean over realizations\n",
    "# (P[arams], F[reqs])\n",
    "mean = np.log10(np.mean(gwb_spectra, axis=1))\n",
    "\n",
    "# Smooth Mean Spectra over frequencies\n",
    "## NOTE FOR LUKE - HOW MUCH SMOOTHING DO WE WANT TO DO ?\n",
    "# print(mean.shape)\n",
    "# smooth_mean = sp.signal.savgol_filter(mean, 7, 3, axis=-1)\n",
    "smooth_mean = mean.copy()\n",
    "\n",
    "if np.any(np.isnan(err)):\n",
    "    print('Got a NAN issue')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAR = 0\n",
    "fig, ax = figax(plamp=None, scale='lin')\n",
    "\n",
    "ax.plot(freqs, np.log10(gwb[PAR, :, :NFREQ].T**2), color='C0', alpha=0.3, zorder=0)\n",
    "\n",
    "ax.plot(freqs, mean[PAR], color='C1', label='Mean')\n",
    "ax.plot(freqs, smooth_mean[PAR], color='C3', label='Smoothed Mean')\n",
    "ax.fill_between(freqs, (mean[PAR]-err[PAR]), (mean[PAR]+err[PAR]), color='C1', alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel(r'GW Frequency [yr$^{-1}$]')\n",
    "ax.set_ylabel(r'$h_{c}^{2}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1955c",
   "metadata": {},
   "source": [
    "## Train GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a GP class containing the kernel parameter priors and a log-likelihood\n",
    "\n",
    "class GP:\n",
    "    \n",
    "    def __init__(self, x, y, yerr=None):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yerr = yerr\n",
    "        \n",
    "        # The number of GP parameters is one more than the number of spectra parameters.\n",
    "        # self.pmax = np.array([20.0, 20.0, 20.0, 20.0, 20.0, 20.0]) # sampling ranges\n",
    "        # self.pmin = np.array([-20.0, -20.0, -20.0, -20.0, -20.0, -20.0])\n",
    "        self.pmin = np.array([-20.0, -20.0])\n",
    "        self.pmax = np.array([20.0, 20.0]) # sampling ranges\n",
    "\n",
    "        self.emcee_flatchain = None\n",
    "        self.emcee_flatlnprob = None\n",
    "        self.emcee_kernel_map = None\n",
    "    \n",
    "    def lnprior(self, p):\n",
    "        logp = 0.0\n",
    "    \n",
    "        if np.all(p <= self.pmax) and np.all(p >= self.pmin):\n",
    "            logp = np.log(1.0 / (self.pmax - self.pmin))\n",
    "            logp = np.sum(logp)\n",
    "        else:\n",
    "            logp = -np.inf\n",
    "\n",
    "        return logp\n",
    "\n",
    "    def lnlike(self, p):\n",
    "\n",
    "        # Update the kernel and compute the lnlikelihood.\n",
    "        a, tau = np.exp(p[0]), np.exp(p[1:])\n",
    "        \n",
    "        try:\n",
    "            gp = george.GP(a * kernels.ExpSquaredKernel(tau, ndim=len(tau)))\n",
    "            #gp = george.GP(a * kernels.Matern32Kernel(tau))\n",
    "            gp.compute(self.x, self.yerr)\n",
    "            lnlike = gp.lnlikelihood(self.y, quiet=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            lnlike = -np.inf\n",
    "        \n",
    "        return lnlike\n",
    "    \n",
    "    def lnprob(self, p):\n",
    "        return self.lnprior(p) + self.lnlike(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the spectra data!\n",
    "\n",
    "# The \"y\" data are the means and errors for the spectra at each point in parameter space\n",
    "yobs = smooth_mean.copy() #mean.copy()\n",
    "yerr = err.copy()\n",
    "\n",
    "## Find mean in each frequency bin (remove it before analyzing with the GP) ##\n",
    "# This allows the GPs to oscillate around zero, where they are better behaved.\n",
    "yobs_mean = np.mean(yobs, axis=0)\n",
    "# MAKE SURE TO SAVE THESE VALUES - THE GP IS USELESS WITHOUT THEM !\n",
    "# np.save('./Luke_Spectra_MEANS.npy', yobs_mean)\n",
    "\n",
    "yobs -= yobs_mean[np.newaxis, :]\n",
    "\n",
    "## The \"x\" data are the actual parameter values\n",
    "xobs = np.zeros((num_pars, 1))\n",
    "xobs[:, 0] = np.log10(mmbulge_norm)\n",
    "\n",
    "#['eccs_mu', 'hard_gamma', 'MM2013_amp', 'MM2013_slope', 'tdelay']\n",
    "# for ii in range(120):\n",
    "#     xobs[ii,0] = spectra['eccs_mu'][ii]\n",
    "#     xobs[ii,1] = spectra['hard_gamma'][ii]\n",
    "#     xobs[ii,2] = spectra['MM2013_amp'][ii]\n",
    "#     xobs[ii,3] = spectra['MM2013_slope'][ii]\n",
    "#     xobs[ii,4] = spectra['tdelay'][ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a list of GP kernels and models [one for each frequency]\n",
    "gp_george = []\n",
    "k = []\n",
    "\n",
    "for freq_ind in range(len(freqs)):\n",
    "    gp_george.append(GP(xobs, yobs[:, freq_ind], yerr[:, freq_ind]))\n",
    "    k.append(1.0 * kernels.ExpSquaredKernel([2.0], ndim=1))\n",
    "\n",
    "num_kpars = len(k[freq_ind])\n",
    "    \n",
    "print(num_kpars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Sample the posterior distribution of the kernel parameters \n",
    "# to find MAP value for each frequency. \n",
    "\n",
    "# THIS WILL TAKE A WHILE... (~ 1 min per frequency)\n",
    "\n",
    "sampler = [0.0]*len(freqs)\n",
    "for freq_ind in range(len(freqs)):\n",
    "    t_start = time.time()\n",
    "    \n",
    "    # Set up the sampler.\n",
    "    nwalkers, ndim = 36, num_kpars\n",
    "    sampler[freq_ind] = emcee.EnsembleSampler(nwalkers, ndim, gp_george[freq_ind].lnprob)\n",
    "\n",
    "    # Initialize the walkers.\n",
    "    p0 = [np.log([1.0, 1.0]) + 1e-4 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "    print(freq_ind, \"Running burn-in\")\n",
    "    p0, lnp, _ = sampler[freq_ind].run_mcmc(p0, 750)\n",
    "    sampler[freq_ind].reset()\n",
    "\n",
    "    print(freq_ind, \"Running second burn-in\")\n",
    "    p = p0[np.argmax(lnp)]\n",
    "    p0 = [p + 1e-8 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "    p0, _, _ = sampler[freq_ind].run_mcmc(p0, 750)\n",
    "    sampler[freq_ind].reset()\n",
    "\n",
    "    print(freq_ind, \"Running production\")\n",
    "    p0, _, _ = sampler[freq_ind].run_mcmc(p0, 1500)\n",
    "    \n",
    "    print('Completed in {} min'.format((time.time()-t_start)/60.) , '\\n')\n",
    "    if freq_ind > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ffe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e25619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's take a look at the posterior distribution of the \n",
    "# kernel parameters at a frequency [ind] of our choice.\n",
    "\n",
    "ind = 1\n",
    "\n",
    "fig = corner.corner(sampler[ind].flatchain, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Populate the GP class with the details of the kernel \n",
    "## MAP values for each frequency.\n",
    "\n",
    "for ii in range(len(freqs)):\n",
    "    gp_george[ii].chain = None \n",
    "    gp_george[ii].lnprob = None \n",
    "    \n",
    "    gp_george[ii].kernel_map = sampler[ii].flatchain[np.argmax(sampler[ii].flatlnprobability)] \n",
    "    #print(ii, gp_george[ii].kernel_map)\n",
    "    \n",
    "    # add-in mean yobs (freq) values\n",
    "    gp_george[ii].mean_spectra = yobs_mean[ii]\n",
    "    if ii > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53052449",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set-up GP predictions ##\n",
    "# If you are running this part of the code separately from the section above, \n",
    "# you will need to re-define the GP class from above for this step to work!\n",
    "\n",
    "gp = []\n",
    "# GP_freqs = np.arange(1.,31.) / (20*365.25*86400.) \n",
    "\n",
    "# for ii in range(len(GP_freqs)):\n",
    "for ii in range(3):\n",
    "    gp_kparams = np.exp(gp_george[ii].kernel_map)\n",
    "\n",
    "    gp.append(george.GP(gp_kparams[0] * \\\n",
    "            george.kernels.ExpSquaredKernel(gp_kparams[1:],ndim=len(gp_kparams[1:])) ) )\n",
    "\n",
    "    gp[ii].compute(gp_george[ii].x, gp_george[ii].yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e25b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmbulge_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad08f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a realization from the GP ##\n",
    "PAR = 3\n",
    "\n",
    "#  A reminder of the spectra parameters:\n",
    "# ['eccs_mu', 'hard_gamma', 'MM2013_amp', 'MM2013_slope', 'tdelay']\n",
    "# env_param = np.array([5.6249, -0.0807,  8.8394,  1.284 ,  5.9822])\n",
    "# env_param = np.array([41.0])\n",
    "env_param = np.log10(np.array([mmbulge_norm[PAR]]))\n",
    "\n",
    "# rho_pred = np.zeros((len(GP_freqs), 2))\n",
    "rho_pred = np.zeros((3, 2))\n",
    "for ii, freq in enumerate(freqs):\n",
    "    mu_pred, cov_pred = gp[ii].predict(gp_george[ii].y, [env_param])\n",
    "    if np.diag(cov_pred) < 0.0:\n",
    "        rho_pred[ii, 0], rho_pred[ii, 1] = mu_pred, 1e-5 * mu_pred\n",
    "        print(bad)\n",
    "    else:\n",
    "        rho_pred[ii, 0], rho_pred[ii, 1] = mu_pred, np.sqrt(np.diag(cov_pred))\n",
    "\n",
    "    if ii > 1:\n",
    "        break\n",
    "\n",
    "## transforming from zero-mean unit-variance variable to rho\n",
    "rho = np.array([gp_george[ii].mean_spectra for ii in range(len(freqs))]) + rho_pred[:, 0]\n",
    "\n",
    "hc = np.sqrt(10**rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dee53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a plot ##\n",
    "\n",
    "# the raw spectra #\n",
    "# for ii in range(100):\n",
    "plt.loglog(freqs, gwb[PAR, :, :NFREQ].T, color='C0', alpha=0.2, zorder=0)\n",
    "\n",
    "# plt.loglog(spectra['freqs'][:30]/(365.25*86400.), spectra['gwb'][3,:30,ii], color='C0', alpha=0.2, zorder=0, label='Original Spectra')\n",
    "\n",
    "# the smoothed mean #\n",
    "plt.loglog(freqs, np.sqrt(10**smooth_mean[PAR, :NFREQ]), color='C1', ls='--', label='Smoothed Mean', lw=2)\n",
    "\n",
    "# the GP realization #\n",
    "plt.semilogx(freqs, hc, color='C3', lw=2.5, label='GP')\n",
    "plt.fill_between(freqs, np.sqrt(10**(rho + rho_pred[:, 1])), np.sqrt(10**(rho - rho_pred[:, 1])), color='C3', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Observed GW Frequency [yr$^{-1}$]')\n",
    "# plt.xlim(1e-9,7e-8)\n",
    "plt.ylabel(r'$h_{c} (f)$')\n",
    "# plt.ylim(1e-16, 1e-13)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "#plt.savefig('./TrainedGP.pdf', bbox_inches='tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42dc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwb.shape, freqs.shape, hc.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
