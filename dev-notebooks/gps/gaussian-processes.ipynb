{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through how to set-up a GP from any given bank of spectra. \n",
    "\n",
    "The GPs come from the python package `george` and we \"train\" them using the package `emcee`. \n",
    "\n",
    "Once the GP is trained, we export it as a pickle object to then use with PTA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import sys,os,glob,h5py,time\n",
    "import scipy.signal as ssig\n",
    "import scipy.interpolate as interp\n",
    "\n",
    "import scipy.linalg as sl\n",
    "import scipy.special as ss\n",
    "import scipy.constants as sc\n",
    "import scipy.misc as scmisc\n",
    "import scipy.integrate as si\n",
    "\n",
    "import george\n",
    "import george.kernels as kernels\n",
    "import emcee, corner, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib as mpl\n",
    "# Silence annoying numpy errors\n",
    "np.seterr(divide='ignore', invalid='ignore', over='ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Plotting settings\n",
    "mpl.rc('font', **{'family': 'serif', 'sans-serif': ['Times'], 'size': 15})\n",
    "mpl.rc('lines', solid_capstyle='round')\n",
    "mpl.rc('mathtext', fontset='cm')\n",
    "mpl.style.use('default')   # avoid dark backgrounds from dark theme vscode\n",
    "plt.rcParams.update({'grid.alpha': 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spectra\n",
    "\n",
    "    The first step is to load the bank of spectra. \n",
    "    Make sure to double check that dimensionality of the parameter space, and get the parameter limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Spectra from Luke\n",
    "fname = \"/Users/lzkelley/programs/nanograv/ng15yr_astro_interp/Illustris_TestSpectra_N100_Obs20yr__mm13.hdf5\"\n",
    "spectra = h5py.File(fname, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spectra.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra['gwb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(spectra['eccs_mu']), np.max(spectra['eccs_mu']))\n",
    "print(np.min(spectra['hard_gamma']), np.max(spectra['hard_gamma']))\n",
    "print(np.min(spectra['mm13_amp']), np.max(spectra['mm13_amp']))\n",
    "print(np.min(spectra['mm13_slope']), np.max(spectra['mm13_slope']))\n",
    "print(np.min(spectra['tdelay']), np.max(spectra['tdelay']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the mean and std from all spectra realizations\n",
    "    At each point in parameter space, we need to find the mean value and the standard deviation from all of the realizations that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE - Only need to train GP on number of frequencies in PTA analysis !\n",
    "NFREQS = 6\n",
    "\n",
    "gwb_spectra = spectra['gwb'][:,:NFREQS,:]**2\n",
    "\n",
    "# Find all of the zeros and set them to be h_c = 1e-20\n",
    "low_ind = np.where(gwb_spectra < 1e-40)\n",
    "gwb_spectra[low_ind] = 1e-40\n",
    "\n",
    "\n",
    "# Find mean over 100 realizations\n",
    "mean = np.log10(np.mean(gwb_spectra, axis=-1))\n",
    "\n",
    "# Smooth Mean Spectra\n",
    "## NOTE FOR LUKE - HOW MUCH SMOOTHING DO WE WANT TO DO ?\n",
    "# smooth_mean = ssig.savgol_filter(mean, 7, 3)\n",
    "\n",
    "# Find std\n",
    "err = np.std(np.log10(gwb_spectra), axis=-1)\n",
    "\n",
    "if np.any(np.isnan(err)):\n",
    "    print('Got a NAN issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is an example plot of the smoothed mean, the mean and standard deviation\n",
    "## and all of the spectra realizations, for a random point in parameter space.\n",
    "\n",
    "for ii in range(100):\n",
    "    plt.loglog(spectra['freqs'][:NFREQS], spectra['gwb'][0,:NFREQS,ii]**2, color='C0', alpha=0.3, zorder=0)\n",
    "plt.loglog(spectra['freqs'][:NFREQS], spectra['gwb'][0,:NFREQS,0]**2, color='C0', alpha=0.3, zorder=0, label='100 Spectra')\n",
    "plt.loglog(spectra['freqs'][:NFREQS], 10**mean[0], color='C1', label='Mean')\n",
    "# plt.loglog(spectra['freqs'][:NFREQS], 10**smooth_mean[0], color='C3', label='Smoothed Mean')\n",
    "plt.fill_between(spectra['freqs'][:NFREQS], 10**(mean[0]-err[0]), 10**(mean[0]+err[0]), color='C1', alpha=0.5)\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(r'GW Frequency [yr$^{-1}$]')\n",
    "plt.ylabel(r'$h_{c}^{2}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GP\n",
    "\n",
    "    The next step is to set up the GP class.\n",
    "    Things to note:\n",
    "        - need to make sure that the GP has the same dimensionality as the parameter space from the spectra.\n",
    "        - the GPs work better when they are trained on zero-mean data, so it's very important that we remove the mean values for the spectra at each frequency, BUT these values HAVE TO BE SAVED, because they are required to extract meaningful information back out of the GP once it is trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a GP class containing the kernel parameter priors and a log-likelihood\n",
    "\n",
    "class gaussproc(object):\n",
    "    \n",
    "    def __init__(self, x, y, yerr=None):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yerr = yerr\n",
    "        \n",
    "        # The number of GP parameters is one more than the number of spectra parameters.\n",
    "        self.pmax = np.array([20.0, 20.0, 20.0, 20.0, 20.0, 20.0]) # sampling ranges\n",
    "        self.pmin = np.array([-20.0, -20.0, -20.0, -20.0, -20.0, -20.0])\n",
    "        self.emcee_flatchain = None\n",
    "        self.emcee_flatlnprob = None\n",
    "        self.emcee_kernel_map = None\n",
    "    \n",
    "    def lnprior(self, p):\n",
    "    \n",
    "        logp = 0.\n",
    "    \n",
    "        if np.all(p <= self.pmax) and np.all(p >= self.pmin):\n",
    "            logp = np.sum(np.log(1/(self.pmax-self.pmin)))\n",
    "        else:\n",
    "            logp = -np.inf\n",
    "\n",
    "        return logp\n",
    "\n",
    "    def lnlike(self, p):\n",
    "\n",
    "        # Update the kernel and compute the lnlikelihood.\n",
    "        a, tau = np.exp(p[0]), np.exp(p[1:])\n",
    "        \n",
    "        lnlike = 0.0\n",
    "        try:\n",
    "            gp = george.GP(a * kernels.ExpSquaredKernel(tau, ndim=len(tau)))\n",
    "            #gp = george.GP(a * kernels.Matern32Kernel(tau))\n",
    "            gp.compute(self.x, self.yerr)\n",
    "            lnlike = gp.lnlikelihood(self.y, quiet=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            lnlike = -np.inf\n",
    "        \n",
    "        return lnlike\n",
    "    \n",
    "    def lnprob(self, p):\n",
    "        return self.lnprior(p) + self.lnlike(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the spectra data!\n",
    "\n",
    "# The \"y\" data are the means and errors for the spectra at each point in parameter space\n",
    "# yobs = smooth_mean.copy() #mean.copy()\n",
    "yobs = mean.copy() #mean.copy()\n",
    "yerr = err.copy()\n",
    "GP_freqs = spectra['freqs'][:NFREQS].copy()\n",
    "\n",
    "## Find mean in each frequency bin (remove it before analyzing with the GP) ##\n",
    "# This allows the GPs to oscillate around zero, where they are better behaved.\n",
    "yobs_mean = np.mean(yobs,axis=0)\n",
    "# MAKE SURE TO SAVE THESE VALUES - THE GP IS USELESS WITHOUT THEM !\n",
    "np.save('./Luke_Spectra_MEANS.npy', yobs_mean)\n",
    "\n",
    "yobs -= yobs_mean[None,:]\n",
    "\n",
    "xx = GP_freqs\n",
    "for ii in range(yobs.shape[0]):\n",
    "    plt.loglog(xx, yobs[ii]**2, color='C0', alpha=0.3, zorder=0, label='100 Spectra')\n",
    "\n",
    "# plt.loglog(xx, 10**mean[0], color='C1', label='Mean')\n",
    "# # plt.loglog(spectra['freqs'][:NFREQS], 10**smooth_mean[0], color='C3', label='Smoothed Mean')\n",
    "plt.fill_between(xx, 10**(-err[0]), 10**(err[0]), color='C1', alpha=0.5)\n",
    "# plt.legend(loc=2)\n",
    "# plt.xlabel(r'GW Frequency [yr$^{-1}$]')\n",
    "# plt.ylabel(r'$h_{c}^{2}$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The \"x\" data are the actual parameter values\n",
    "xobs = np.zeros((120, 5))\n",
    "\n",
    "# ['eccs_mu', 'hard_gamma', 'mm13_amp', 'mm13_slope', 'tdelay']\n",
    "xobs[:, 0] = spectra['eccs_mu'][:]\n",
    "xobs[:, 1] = spectra['hard_gamma'][:]\n",
    "xobs[:, 2] = spectra['mm13_amp'][:]\n",
    "xobs[:, 3] = spectra['mm13_slope'][:]\n",
    "xobs[:, 4] = spectra['tdelay'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a list of GP kernels and models [one for each frequency]\n",
    "\n",
    "gp_george = []\n",
    "k = []\n",
    "\n",
    "for freq_ind in range(len(GP_freqs)):\n",
    "    \n",
    "    gp_george.append(gaussproc(xobs, yobs[:,freq_ind], yerr[:,freq_ind]))\n",
    "    k.append( 1.0 * kernels.ExpSquaredKernel([2.0,2.0,2.0,2.0,2.0], ndim=5) )\n",
    "    num_kpars = len(k[freq_ind])\n",
    "    \n",
    "print(num_kpars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the posterior distribution of the kernel parameters \n",
    "# to find MAP value for each frequency. \n",
    "\n",
    "# THIS WILL TAKE A WHILE... (~ 1 min per frequency)\n",
    "\n",
    "sampler = [0.0]*len(GP_freqs)\n",
    "for freq_ind in range(len(GP_freqs)):\n",
    "    t_start = time.time()\n",
    "    \n",
    "    # Set up the sampler.\n",
    "    nwalkers, ndim = 36, num_kpars\n",
    "    sampler[freq_ind] = emcee.EnsembleSampler(nwalkers, ndim, gp_george[freq_ind].lnprob)\n",
    "\n",
    "    # Initialize the walkers.\n",
    "    p0 = [np.log([1.,1.,1.,1.,1.,1.]) + 1e-4 * np.random.randn(ndim)\n",
    "          for i in range(nwalkers)]\n",
    "\n",
    "    print(freq_ind, \"Running burn-in\")\n",
    "    p0, lnp, _ = sampler[freq_ind].run_mcmc(p0, 750)\n",
    "    sampler[freq_ind].reset()\n",
    "\n",
    "    print(freq_ind, \"Running second burn-in\")\n",
    "    p = p0[np.argmax(lnp)]\n",
    "    p0 = [p + 1e-8 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "    p0, _, _ = sampler[freq_ind].run_mcmc(p0, 750)\n",
    "    sampler[freq_ind].reset()\n",
    "\n",
    "    print(freq_ind, \"Running production\")\n",
    "    p0, _, _ = sampler[freq_ind].run_mcmc(p0, 1500)\n",
    "    \n",
    "    print('Completed in {} min'.format((time.time()-t_start)/60.) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's take a look at the posterior distribution of the \n",
    "# kernel parameters at a frequency [ind] of our choice.\n",
    "\n",
    "ind = 0\n",
    "\n",
    "fig = corner.corner(sampler[ind].flatchain, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Populate the GP class with the details of the kernel \n",
    "## MAP values for each frequency.\n",
    "\n",
    "for ii in range(len(GP_freqs)):\n",
    "    \n",
    "    gp_george[ii].chain = None \n",
    "    gp_george[ii].lnprob = None \n",
    "    \n",
    "    gp_george[ii].kernel_map = sampler[ii].flatchain[np.argmax(sampler[ii].flatlnprobability)] \n",
    "    #print(ii, gp_george[ii].kernel_map)\n",
    "    \n",
    "    # add-in mean yobs (freq) values\n",
    "    gp_george[ii].mean_spectra = yobs_mean[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the trained GP as a pickle to be used with PTA data!\n",
    "pickle.dump(gp_george, open( \"LukeSpectra_GP_120nodes_20yr_30freqs.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the GP\n",
    "    The following is some example code looking at how to extract predictions from the GP and test it against the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"LukeSpectra_GP_120nodes_20yr_30freqs.pkl\", \"rb\") as f:\n",
    "    gp_george = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set-up GP predictions ##\n",
    "# If you are running this part of the code separately from the section above, \n",
    "# you will need to re-define the GP class from above for this step to work!\n",
    "\n",
    "gp = []\n",
    "GP_freqs = np.arange(1.,31.) / (20*365.25*86400.) \n",
    "\n",
    "for ii in range(len(GP_freqs)):\n",
    "    gp_kparams = np.exp(gp_george[ii].kernel_map)\n",
    "\n",
    "    gp.append(george.GP(gp_kparams[0] * \\\n",
    "            george.kernels.ExpSquaredKernel(gp_kparams[1:],ndim=len(gp_kparams[1:])) ) )\n",
    "\n",
    "    gp[ii].compute(gp_george[ii].x, gp_george[ii].yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a realization from the GP ##\n",
    "\n",
    "#  A reminder of the spectra parameters:\n",
    "# ['eccs_mu', 'hard_gamma', 'mm13_amp', 'mm13_slope', 'tdelay']\n",
    "env_param = np.array([5.6249, -0.0807,  8.8394,  1.284 ,  5.9822])\n",
    "\n",
    "rho_pred = np.zeros((len(GP_freqs),2))\n",
    "for ii,freq in enumerate(GP_freqs):\n",
    "    mu_pred, cov_pred = gp[ii].predict(gp_george[ii].y, [env_param])\n",
    "    if np.diag(cov_pred) < 0.0:\n",
    "        rho_pred[ii,0], rho_pred[ii,1] = mu_pred, 1e-5 * mu_pred\n",
    "        print(bad)\n",
    "    else:\n",
    "        rho_pred[ii,0], rho_pred[ii,1] = mu_pred, np.sqrt(np.diag(cov_pred))\n",
    "\n",
    "## transforming from zero-mean unit-variance variable to rho\n",
    "rho = np.array([gp_george[ii].mean_spectra for ii in range(len(GP_freqs))]) + rho_pred[:,0]\n",
    "\n",
    "hc = np.sqrt(10**rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a plot ##\n",
    "\n",
    "# the raw spectra #\n",
    "for ii in range(100):\n",
    "    plt.loglog(spectra['freqs'][:30]/(365.25*86400.), spectra['gwb'][3,:30,ii], color='C0', alpha=0.2, zorder=0)\n",
    "plt.loglog(spectra['freqs'][:30]/(365.25*86400.), spectra['gwb'][3,:30,ii], color='C0', alpha=0.2, zorder=0, label='Original Spectra')\n",
    "\n",
    "# the smoothed mean #\n",
    "plt.loglog(spectra['freqs'][:30]/(365.25*86400.), np.sqrt(10**smooth_mean[3]), color='C1', label='Smoothed Mean', lw=2)\n",
    "\n",
    "# the GP realization #\n",
    "plt.semilogx(GP_freqs/(365.25*86400.), hc, color='C3', lw=2.5, label='GP')\n",
    "plt.fill_between(GP_freqs/(365.25*86400.), np.sqrt(10**(rho+rho_pred[:,1])), np.sqrt(10**(rho-rho_pred[:,1])), color='C3', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.xlabel('Observed GW Frequency [Hz]')\n",
    "plt.xlim(1e-9,7e-8)\n",
    "plt.ylabel(r'$h_{c} (f)$')\n",
    "plt.ylim(1e-16, 1e-13)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "#plt.savefig('./TrainedGP.pdf', bbox_inches='tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f0c7602c82e39efa19a01e5e068584db7a6d17aff8711ab06660aac81377393"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
