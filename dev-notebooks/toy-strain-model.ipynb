{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../notebooks/init.ipy\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Builtin packages\n",
    "from importlib import reload\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# standard secondary packages\n",
    "import astropy as ap\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "# development packages\n",
    "import kalepy as kale\n",
    "import kalepy.utils\n",
    "import kalepy.plot\n",
    "\n",
    "# --- Holodeck ----\n",
    "import holodeck as holo\n",
    "import holodeck.sam\n",
    "from holodeck import cosmo, utils, plot\n",
    "from holodeck.constants import MSOL, PC, YR, MPC, GYR, SPLC, NWTG\n",
    "import holodeck.gravwaves\n",
    "import holodeck.evolution\n",
    "import holodeck.population\n",
    "\n",
    "# Silence annoying numpy errors\n",
    "np.seterr(divide='ignore', invalid='ignore', over='ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Plotting settings\n",
    "mpl.rc('font', **{'family': 'serif', 'sans-serif': ['Times'], 'size': 15})\n",
    "mpl.rc('lines', solid_capstyle='round')\n",
    "mpl.rc('mathtext', fontset='cm')\n",
    "mpl.style.use('default')   # avoid dark backgrounds from dark theme vscode\n",
    "plt.rcParams.update({'grid.alpha': 0.5})\n",
    "\n",
    "# Load log and set logging level\n",
    "log = holo.log\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zcode.math as zmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figax_gwb(**kw):\n",
    "    kwargs = dict(xlabel='GW Frequency $[\\mathrm{yr}^{-1}]$', ylabel='Characteristic Strain')\n",
    "    kwargs.update(kw)\n",
    "    fig, ax = plot.figax(**kwargs)\n",
    "    plot._twin_hz(ax, fs=10)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define LaTeX macros/commands** (they're invisible!)\n",
    "\n",
    "$\\newcommand{\\mchirp}{\\mathcal{M}}$\n",
    "$\\newcommand{\\msol}{M_\\odot}$\n",
    "\n",
    "$\\newcommand{\\lr}[1]{\\left({#1}\\right)}$\n",
    "$\\newcommand{\\lrangle}[1]{\\langle{#1}\\rangle}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idealized GWB Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a population of binaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will randomly create some number of sample binaries, as a toy model.  From that, we will calculate a number-density distribution of binaries.  Typically, the number density would be calculated directly (e.g. from semi-analytic models), but here we start from a finite population to more easily allow for cross-checking the results.  The number-density distribution can also be used to construct realizations of discrete binary populations, including full universe (i.e. light-cone) populations.  Because we are not starting from the number-density, we can also cross-check these discretized populations with our starting (discrete) population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set basic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = 1e6\n",
    "MASS_EXTR = [1e6, 1e10]\n",
    "# TMAX = (2.0 * YR)\n",
    "# NFREQS = 100\n",
    "TMAX = (20.0 * YR)\n",
    "NFREQS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fobs_gw = np.arange(1, NFREQS+1) / TMAX\n",
    "fobs_gw_edges = np.concatenate([fobs_gw - fobs_gw[0]/2, [fobs_gw[-1] + fobs_gw[0]/2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct binary total-masses\n",
    "masses = zmath.random_power(MASS_EXTR, -3, NUM) * MSOL\n",
    "# Set fixed values of redshift and mass-ratio\n",
    "redz = 0.1\n",
    "mrat = 0.3\n",
    "\n",
    "fig, ax = plot.figax()\n",
    "kale.dist1d((masses/MSOL), carpet=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Analytic (SA) Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GWB characteristic strain spectrum can be calculated **semi-analytically** using a volumetric number-density of sources $n(M, q, z) = dN/dV_c$, as [Phinney 2001, Eq. 5] or [Enoki & Nagashima 2007, Eq. 3.6]:\n",
    "\n",
    "$$ h_c^2 = \\frac{4G}{\\pi c^2 f} \\int dM \\, dq \\, dz \\, \\frac{d^3 n(M, q, z)}{dM \\, dq \\, dz} \\, \\left( \\frac{dE_{GW}(M, q)}{d f_r}\\right)_{f_r = f(1+z)}$$\n",
    "\n",
    "Assuming circular, GW-driven orbits, this can be simplified to [Enoki & Nagashima 2007, Eq.3.11]:\n",
    "\n",
    "$$ h_c^2 = \\frac{4\\pi}{3 c^2} (\\pi f)^{-4/3} \\int dM \\, dq \\, dz \\, \\frac{d^3 n(M, q, z)}{dM \\, dq \\, dz} \\, \\frac{(G\\mathcal{M})^{5/3}}{(1+z)^{1/3}}$$\n",
    "\n",
    "Typically the number density will be calculated based on observations or phenomenological grounds.  For example, rough estimates of the occurrence rates of binaries, or based on Semi-Analytic or Semi-Empirical Models (SAMs / SEMs) of populations of galaxies, galaxy mergers, and black hole binary populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a Number-Density distribution of MBH binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBINS = 123\n",
    "mbin_edges = zmath.spacing(masses, 'log', NBINS+1)\n",
    "mbin_cents = 0.5 * (mbin_edges[:-1] + mbin_edges[1:])\n",
    "# calculate comoving-volume for the finite population of binaries producing the \n",
    "vcom = cosmo.comoving_volume(redz).cgs.value\n",
    "\n",
    "SHAPE = (NBINS,)\n",
    "ndens = np.zeros(SHAPE)\n",
    "ndens, *_ = sp.stats.binned_statistic(masses, None, statistic='count', bins=mbin_edges)\n",
    "ndens /= np.diff(mbin_edges)\n",
    "ndens /= vcom\n",
    "\n",
    "sfig, ax = plot.figax(xlabel='Total Mass [$M_\\odot$]', ylabel='Differential number density $[M_\\odot^{-1} \\, \\\\mathrm{Mpc}^{-3}]$')\n",
    "plot.draw_hist_steps(ax, mbin_edges/MSOL, ndens*MSOL*(MPC**3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate GWB assuming circular, GW-driven evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mchirp_edges = utils.chirp_mass_mtmr(mbin_edges, mrat)\n",
    "mchirp_cents = 0.5 * (mchirp_edges[:-1] + mchirp_edges[1:])\n",
    "integrand = ndens * np.power(NWTG * mchirp_cents, 5.0/3.0) * np.power(1+redz, -1.0/3.0)\n",
    "\n",
    "gwb_sa = ((4.0 * np.pi) / (3 * SPLC**2)) * np.power(np.pi*fobs_gw, -4.0/3.0) * np.sum(integrand * np.diff(mbin_edges))\n",
    "gwb_sa = np.sqrt(gwb_sa)\n",
    "\n",
    "xx = fobs_gw * YR\n",
    "fig, ax = figax_gwb()\n",
    "ax.plot(xx, gwb_sa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo (MC) Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GWB can also be calculated explicitly from the full population of binaries in the universe [Sesana et al. 2008, Eq.~10], \n",
    "$$h_c^2(f) = \\int_0^\\infty \\!\\! dM \\, dq \\, dz \\; \\frac{d^4 N}{dM \\, dq \\, dz \\, d\\ln f_r} \\; h^2(f_r),$$\n",
    "\n",
    "where the spectral GW strain (*not* characteristic strain) for a circular binary is,\n",
    "\n",
    "$$h(f_r) = \\frac{8}{10^{1/2}} \\frac{(G\\mathcal{M})^{5/3}}{c^4 d_c} (2\\pi f_r)^{2/3}.$$\n",
    "\n",
    "From [Sesana et al. 2008, Eq.6] we can write,\n",
    "\n",
    "$$\\frac{d^4 N}{dM \\, dq \\, dz \\, d\\ln f_r} = \\frac{d^3 n_c}{dM \\, dq \\, dz} \\frac{dz}{dt} \\frac{dt}{d\\ln f_r} \\frac{d V_c}{dz}.$$\n",
    "\n",
    "The standard cosmographic relations are [Hogg 1999],\n",
    "\n",
    "$$\\frac{dz}{dt} = H_0 (1+z) E(z) \\\\\n",
    "    \\frac{d V_c}{dz} = 4\\pi \\frac{c}{H_0} \\frac{d_c^2}{E(z)} \\\\\n",
    "    d_L = d_c \\, (1+z)$$\n",
    "\n",
    "Combining these, we obtain:\n",
    "\n",
    "$$h_c^2(f) = \\int_0^\\infty \\!\\! dM \\, dq \\, dz \\; \\frac{d^3 n_c}{dM \\, dq \\, dz} \\, h^2(f_r) \\, 4\\pi c \\, d_c^2 (1+z) \\, \\frac{f_r}{df_r / dt}.$$\n",
    "\n",
    "The hardening timescale for a circular, GW-driven binary is:\n",
    "\n",
    "$$\\tau_{GW} \\equiv \\frac{f_r}{\\left[df_r/dt\\right]_{GW}} = \\frac{5}{96} \\frac{c^5}{(G \\mathcal{M})^{5/3}} (2\\pi f_r)^{-8/3}.$$\n",
    "\n",
    "Plugging this in to the previous relation gives:\n",
    "\n",
    "$$h_c^2(f) = \\frac{20\\pi c^6}{96} \\int_0^\\infty \\!\\! dM \\, dq \\, dz \\; \\frac{d^3 n_c}{dM \\, dq \\, dz} \\, h^2(f_r) \\, \\frac{d_c^2 (1+z)}{(G \\mathcal{M})^{5/3}} (2\\pi f_r)^{-8/3}.$$\n",
    "\n",
    "Note that this is ultimately the same expression as for the Semi-Analytic calculation previously.  But we can use it in a slightly different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gwb_number_from_ndens(ndens, medges, mc_cents, dcom, fro):\n",
    "    # `fro` = frst_orb\n",
    "    integrand = ((20*np.pi*(SPLC**6))/96) * ndens * np.diff(medges)\n",
    "    integrand *= (dcom**2) * (1.0 + redz) * np.power(NWTG * mc_cents, -5.0/3.0)\n",
    "    integrand = integrand[:, np.newaxis] * np.power(2.0*np.pi*fro, -8.0/3.0)\n",
    "    return integrand\n",
    "\n",
    "# sepa_isco = 6 * NWTG * mbin_cents / SPLC**2\n",
    "# frst_orb_isco = utils.kepler_freq_from_sepa(mbin_cents, sepa_isco)\n",
    "# bads = frst_orb > frst_orb_isco[:, np.newaxis]\n",
    "# merged = np.ones_like(integrand)\n",
    "# merged[bads] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frst_orb = fobs_gw[np.newaxis, :] * (1.0 + redz) / 2.0\n",
    "dcom = cosmo.comoving_distance(redz).cgs.value\n",
    "\n",
    "hs_mc = (8.0 / np.sqrt(10)) * np.power(NWTG * mchirp_cents, 5.0/3.0) / (dcom * (SPLC**4))\n",
    "hs_mc = hs_mc[:, np.newaxis] * np.power(2*np.pi*frst_orb, 2.0/3.0) \n",
    "\n",
    "integrand = gwb_number_from_ndens(ndens, mbin_edges, mchirp_cents, dcom, frst_orb)\n",
    "\n",
    "gwb_mc = np.sum(integrand * (hs_mc**2), axis=0)\n",
    "gwb_mc = np.sqrt(gwb_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figax_gwb()\n",
    "\n",
    "xx = fobs_gw * YR\n",
    "ax.plot(xx, gwb_sa, 'k--', alpha=0.5, label='SA')\n",
    "ax.plot(xx, gwb_mc, label='MC', lw=2.0, alpha=0.7)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization / Realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous calculations (both semi-analytic, and the re-written version) assume a smooth continuous distribution of binaries.  Binaries, however, are discrete: the population is composed of individual systems, and there cannot be fractional systems (as is implicitly assumed above).  To correct this, we can discretize our population into integer multiples of binaries.  At the same time, we can also take into account some measure of cosmic variance - in the form of Poisson variations --- which also gives us multiple 'realizations' of the population.  For a given bin of binaries, instead of using the fractional expectation-value number of binaries, we will draw from a Poisson distribution centered around that value.\n",
    "\n",
    "Note that we are still restricting ourselves to the binned population.  i.e. instead of individual binaries across the parameter space, we are still consider the ``N_i`` binaries in each parameter bin ``i``.  But now we are ensuring that ``N_i`` is an integer, and we can also construct multiple realizations of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NREALS = 100\n",
    "\n",
    "\"\"\"\n",
    "NOTE: `gwb_number_from_ndens` returns ``dN/dln(f)``.  We want to create realizations based on ``N``\n",
    "    the actualy number of binaries.  So we multiply by ``Delta ln(f)``, to get the number of\n",
    "    binaries in each frequency bin (``Delta N_i``).  Then we calculate the discretizations.\n",
    "    Then we divide by ``Delta ln(f)`` again, to get the number of binaries per frequency bin,\n",
    "    needed for the GW characteristic strain calculation.\n",
    "\"\"\"\n",
    "\n",
    "integrand = gwb_number_from_ndens(ndens, mbin_edges, mchirp_cents, dcom, frst_orb)\n",
    "integrand = integrand * np.diff(np.log(fobs_gw_edges))   # get the number of binaries in each frequency bin\n",
    "\n",
    "num_exp = np.sum(integrand[:, 0])\n",
    "print(f\"Expected number of binaries in zero freq bin: {num_exp:.4e}\")\n",
    "\n",
    "realized = np.random.poisson(integrand[..., np.newaxis], size=integrand.shape + (NREALS,))\n",
    "\n",
    "realized = np.random.poisson(integrand[..., np.newaxis], size=integrand.shape + (NREALS,))\n",
    "# convert back to number of binaries per log-frequency interval\n",
    "realized = realized / np.diff(np.log(fobs_gw_edges))[np.newaxis, :, np.newaxis]\n",
    "\n",
    "num_real = np.sum(realized[:, 0, :], axis=0)\n",
    "num_real_ave = np.mean(num_real)\n",
    "num_real_std = np.std(num_real)\n",
    "print(f\"Realized number of binaries in zero freq bin: {num_real_ave:.4e} ± {num_real_std:.2e}\")\n",
    "\n",
    "gwb_mc_real = np.sum(realized * (hs_mc**2)[..., np.newaxis], axis=0)\n",
    "gwb_mc_real = np.sqrt(gwb_mc_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figax_gwb()\n",
    "xx = fobs_gw * YR\n",
    "ax.plot(xx, gwb_sa, 'k--', alpha=0.5, label='SA')\n",
    "ax.plot(xx, gwb_mc, label='MC', lw=2.0, alpha=0.7)\n",
    "\n",
    "color = 'r'\n",
    "gwb_mc_med = np.median(gwb_mc_real, axis=-1)\n",
    "gwb_mc_span = np.percentile(gwb_mc_real, [25, 75], axis=-1)\n",
    "ax.plot(xx, gwb_mc_med, lw=0.5, color=color)\n",
    "ax.fill_between(xx, *gwb_mc_span, alpha=0.25, color=color, label='MC realized')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Population Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number density was calculated from a finite number of binaries, in a finite volume.  Instead of going through the number-density as an intermediate quantity (i.e. binning sample binaries), just use the finite number of binaries directly to calculate the GWB.\n",
    "\n",
    "$$\n",
    "    \\frac{d^3 n_c}{dM \\, dq \\, dz} \\, dM \\, dq \\, dz\n",
    "        \\rightarrow \\frac{1}{V_c} \\sum_i  \\delta(M < M_i < M + \\Delta M) \\cdot \\delta(q < q_i < q + \\Delta q) \\cdot \\delta(z < z_i < z + \\Delta z) \\, F(M, q, z) \\\\\n",
    "        \\rightarrow \\frac{1}{V_c} \\sum_i F(M_i \\,,\\, q_i \\,,\\, z_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcom = cosmo.comoving_distance(redz).cgs.value\n",
    "frst_orb = fobs_gw[np.newaxis, :] * (1.0 + redz) / 2.0\n",
    "mchirp = utils.chirp_mass_mtmr(masses, mrat)\n",
    "\n",
    "hs_fin = (8.0 / np.sqrt(10)) * np.power(NWTG * mchirp, 5.0/3.0) / (dcom * (SPLC**4))\n",
    "hs_fin = hs_fin[:, np.newaxis] * np.power(2*np.pi*frst_orb, 2.0/3.0) \n",
    "\n",
    "integrand = ((20*np.pi*(SPLC**6))/96) / vcom\n",
    "integrand *= (dcom**2) * (1.0 + redz) * np.power(NWTG * mchirp, -5.0/3.0)\n",
    "integrand = integrand[:, np.newaxis] * np.power(2.0*np.pi*frst_orb, -8.0/3.0)\n",
    "\n",
    "gwb_fin = np.sum(integrand * (hs_fin**2), axis=0)\n",
    "gwb_fin = np.sqrt(gwb_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = figax_gwb()\n",
    "xx = fobs_gw * YR\n",
    "ax.plot(xx, gwb_sa, 'k--', label='SA', alpha=0.5, lw=2.0)\n",
    "ax.plot(xx, gwb_mc, lw=2.0, alpha=0.7, label='MC')\n",
    "ax.plot(xx, gwb_fin, lw=2.0, alpha=0.75, label='Finite')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization / Realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way to the MC calculation above, we can discretize and calculate multiple realizations from the starting finite population.  This is a little strange: we start with a finite population, and then construct multiple, new discrete populations from this.  There is a key difference from the starting populations and the new ones: the starting population represents only a fixed volume, while the realizations are very explicitly full Universes.  In this example, the difference is trivial, but if the starting population comes from a finite volume (for example a cosmological hydrodynamic simulation), then the difference is much more important (and useful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: this is quite slow, so only construct a single realization!\n",
    "\n",
    "NREALS = 30\n",
    "realized = integrand * np.diff(np.log(fobs_gw_edges))\n",
    "gwb_fin_real = np.zeros((fobs_gw.size, NREALS))\n",
    "for ii in utils.tqdm(range(NREALS)):\n",
    "    real = np.random.poisson(realized) / np.diff(np.log(fobs_gw_edges))\n",
    "    gwb_fin_real[:, ii] = np.sum(real * (hs_fin**2), axis=0)\n",
    "\n",
    "gwb_fin_real = np.sqrt(gwb_fin_real)\n",
    "\"\"\"\n",
    "\n",
    "DISCRETIZE_FINITE_FLAG = False\n",
    "\n",
    "if DISCRETIZE_FINITE_FLAG:\n",
    "\n",
    "    _dlnf = np.diff(np.log(fobs_gw_edges))\n",
    "    real = np.random.poisson(integrand * _dlnf) / _dlnf\n",
    "    gwb_fin_real = np.sum(real * (hs_fin**2), axis=0)\n",
    "    gwb_fin_real = np.sqrt(gwb_fin_real)\n",
    "\n",
    "    fig, ax = figax_gwb()\n",
    "    xx = fobs_gw * YR\n",
    "    ax.plot(xx, gwb_sa, 'k--', alpha=0.5, label='SA')\n",
    "    ax.plot(xx, gwb_fin, lw=3.0, alpha=0.6, ls=':', label='Finite')\n",
    "    ax.plot(xx, gwb_mc_med, lw=2.0, alpha=0.7, label='MC realized')\n",
    "\n",
    "    color = 'r'\n",
    "    ax.plot(xx, gwb_fin_real, lw=0.75, color=color, alpha=0.5, label='Finite realized')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Re)Sampling Binned Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MC method, we 'discretized' the population to account for finite number effects and Poisson sampling (i.e. a model for cosmic variance).  This was still done to the distribution of binaries in a bin-wise fashion: we would get a 'discretized' number of binaries per bin, for each realization.\n",
    "\n",
    "Here we will construct populations that attempt to better Monte-Carlo sample the binary parameter space.  This is done using the `kalepy.sample_outliers` function.  The idea is that the most interesting parts of parameter space are the bins with expectation values for order-unity binaries, i.e.$\\lrangle{N_i} \\sim 1$.  The motivation is that bins with $\\lrangle{N_i} \\ll 1$ are unlikely to ever produce binaries, and bins with $\\lrangle{N_i} \\gg 1$ are accurately represented by the bin-centroid value, instead of sampling individual binaries explicitly.  The `kalepy.sample_outliers` function thus returns weighted bin-centroids above some critical expectation value, and samples individual binaries for bins below that critical value.\n",
    "\n",
    "The function call looks like, `kalepy.sample_outliers(edges, density, threshold, mass=None)`.  The arguments are as follows:\n",
    "* `edges` : the grid-edges of the parameter space being sampled.  This is a list of arrays, with one array for each dimension of the space.\n",
    "* `density` : the number-density, evaluated at grid-edges, that is sampled from.  \n",
    "* `threshold` : the number of binaries per-bin, below which each binary is sampled.  Bins above this value will return a weighted centroid.  Bins below this value will return the appropriate number of individual binaries each with weight equal to unity.\n",
    "* `mass` : the number of binaries that should be sampled in each bin.  This is an optional argument, and if it is not provided, then `density` is integrated over to calculate `mass`.\n",
    "\n",
    "The return values are `vals, weights` which are:\n",
    "* `vals` : the samples binary parameters, shaped `(D, S)` for `D` dimensions of parameter space, and `S` total number of samples - including both individual binaries, and grid centroids.\n",
    "* `weights` : the weight of each sample, either equal to unity for individual binaries (i.e. for bins below the sampling threshold), or equal to the bin-mass (for bins above the sampling threshold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: sampling the population is somewhat delicate and must be done with care!  See additional notes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrap_cents_to_edges(grid):\n",
    "    ndim = grid.ndim\n",
    "    vals = np.copy(grid)\n",
    "\n",
    "    # Extrapolate to one more point each left and right, along each axis progressively\n",
    "    # (A,B,C,...) ==> (A+2,B,C,...) ==> (A+2,B+2,C,...) ==>  ...  ==> (A+2, B+2, C+2, ...)\n",
    "    for ax in range(ndim):\n",
    "        vals = np.moveaxis(vals, ax, 0)\n",
    "        ll = 2*vals[0] - vals[1]\n",
    "        rr = 2*vals[-1] - vals[-2]\n",
    "        vals = np.concatenate([[ll], vals, [rr]], axis=0)\n",
    "        vals = np.moveaxis(vals, 0, ax)\n",
    "\n",
    "    # Interpolate to mid-points along each axis\n",
    "    # (A+2,B+2,C+2,...) ==> (A+1,B+2,C+2,...) ==> (A+1,B+1,C,...) ==>  ...  ==> (A+1, B+1, C+1, ...)\n",
    "    for ax in range(ndim):\n",
    "        vals = np.moveaxis(vals, ax, 0)\n",
    "        vals = 0.5 * (vals[:-1] + vals[1:])\n",
    "        vals = np.moveaxis(vals, 0, ax)\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = frst_orb[0, 0]\n",
    "frst_orb_edges = np.concatenate([frst_orb[0] - _df/2, [frst_orb[0][-1] + _df/2]])\n",
    "\n",
    "number_resamp = gwb_number_from_ndens(ndens, mbin_edges, mchirp_cents, dcom, frst_orb)\n",
    "number_resamp *= np.diff(np.log(fobs_gw_edges))\n",
    "print(f\"{number_resamp.sum()=:.4e}\")\n",
    "\n",
    "# Convert to differential-density number\n",
    "sample_ndens = number_resamp / np.diff(mbin_edges)[:, np.newaxis]\n",
    "sample_ndens = sample_ndens / np.diff(frst_orb_edges)[np.newaxis, :]\n",
    "sample_ndens = extrap_cents_to_edges(sample_ndens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Full Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses the `kalepy.sample_grid` method to sample *ALL* binaries.  This is extremely slow, and memory intensive.  For large-enough number of binaries, it will likely crash.  Use with caution, and only when the total number of binaries being samples is within the capabilities of the computer -- typically $\\lrangle{N_\\mathrm{total}} \\lesssim 10^7$ or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FULL_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NREALS = 10\n",
    "\n",
    "#!!! NOTE: this is *prohibitively* slow !!!#\n",
    "\n",
    "if SAMPLE_FULL_FLAG:\n",
    "    log.warning(\"!SAMPLING FULL POPULATION IS REALLY SLOW AND MEMORY INTENSIVE!\")\n",
    "    gwb_resamp_full = np.zeros((fobs_gw.size, NREALS))\n",
    "\n",
    "    for ii in utils.tqdm(range(NREALS)):\n",
    "        sample_edges = [np.log10(mbin_edges), np.log(frst_orb_edges)]\n",
    "        vals = kale.sample_grid(sample_edges, sample_ndens, mass=number_resamp)\n",
    "        mm = 10.0 ** vals[0]\n",
    "        frorb = np.e ** vals[1]\n",
    "\n",
    "        dcom = cosmo.comoving_distance(redz).cgs.value\n",
    "        mchirp = utils.chirp_mass_mtmr(mm, mrat)\n",
    "\n",
    "        hs = (8.0 / np.sqrt(10)) * np.power(NWTG * mchirp, 5.0/3.0) / (dcom * (SPLC**4))\n",
    "        hs = hs * np.power(2*np.pi*frorb, 2.0/3.0) \n",
    "\n",
    "        sepa_isco = 6 * NWTG * mm / SPLC**2\n",
    "        frst_orb_isco = utils.kepler_freq_from_sepa(mm, sepa_isco)\n",
    "        bads = frorb > frst_orb_isco\n",
    "        merged = np.ones_like(bads, dtype=float)\n",
    "        merged[bads] = 0.0\n",
    "\n",
    "        fogw = frorb * 2.0 / (1.0 + redz)\n",
    "        hs = merged * (hs**2)\n",
    "        gwb_resamp_full[:, ii], *_ = sp.stats.binned_statistic(fogw, hs, statistic='sum', bins=fobs_gw_edges)\n",
    "        gwb_resamp_full[:, ii] = np.sqrt(gwb_resamp_full[:, ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_FULL_FLAG:\n",
    "\n",
    "    fig, ax = plot.figax()\n",
    "    xx = fobs_gw * YR\n",
    "    ax.plot(xx, gwb_sa, 'k--', lw=1.5, alpha=0.5)\n",
    "    ax.plot(xx, gwb_fin, 'k:', lw=2.0, alpha=0.5)\n",
    "    gwb_mc_med = np.median(gwb_mc, axis=-1)\n",
    "    ax.plot(xx, gwb_mc_med, color='b', lw=2.0, alpha=0.5)\n",
    "\n",
    "    med = np.median(gwb_resamp_full, axis=-1)\n",
    "    ax.plot(xx, med, lw=0.5, color='r')\n",
    "    ax.fill_between(xx, *np.percentile(gwb_resamp_full, [25, 75], axis=-1), alpha=0.5, color='r')\n",
    "\n",
    "    tw = ax.twinx()\n",
    "    tw.plot(xx, gwb_sa/med, 'r--', alpha=0.5)\n",
    "    tw.plot(xx, gwb_mc_med/med, 'b--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 'Outliers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier sampling must be performed carefully, as it can be delicate.  Keep in mind some of the following considerations:\n",
    "* bin centroids are used for bins above the threshold.  The number of bins in the distribution must be sufficiently high such that the centroids are good approximations for the true distribution of values.\n",
    "* consider whether to sample in linear or log space for different parameters.  For example, **for the GWB calculation, sampling mass in linear-space produces better results** and it produces centroids nearer to the strain-weighted mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NREALS = 100\n",
    "\n",
    "gwb_resamp_out = np.zeros((fobs_gw.size, NREALS))\n",
    "sample_threshold = 1e2\n",
    "\n",
    "DOWN = 10.0\n",
    "\n",
    "temp = np.copy(number_resamp) / DOWN\n",
    "\n",
    "for ii in utils.tqdm(range(NREALS)):\n",
    "    # sample_edges = [np.log10(mbin_edges), np.log(frst_orb_edges)]\n",
    "    # vals, weights = kale.sample_outliers(sample_edges, sample_ndens, sample_threshold, mass=number_resamp) \n",
    "    # mm = 10.0 ** vals[0]\n",
    "    # frorb = np.e ** vals[1]\n",
    "    \n",
    "\n",
    "    sample_edges = [mbin_edges, frst_orb_edges]\n",
    "    vals, weights = kale.sample_outliers(sample_edges, sample_ndens, sample_threshold, mass=temp)\n",
    "    mm = vals[0]\n",
    "    frorb = vals[1]\n",
    "    weights = weights * DOWN\n",
    "\n",
    "    dcom = cosmo.comoving_distance(redz).cgs.value\n",
    "    mchirp = utils.chirp_mass_mtmr(mm, mrat)\n",
    "\n",
    "    hs = (8.0 / np.sqrt(10)) * np.power(NWTG * mchirp, 5.0/3.0) / (dcom * (SPLC**4))\n",
    "    hs = hs * np.power(2*np.pi*frorb, 2.0/3.0) \n",
    "\n",
    "    fogw = frorb * 2.0 / (1.0 + redz)\n",
    "\n",
    "    hs_1 = (hs**2) * weights\n",
    "    gwb_resamp_out[:, ii], *_ = sp.stats.binned_statistic(fogw, hs_1, statistic='sum', bins=fobs_gw_edges)\n",
    "    gwb_resamp_out[:, ii] = gwb_resamp_out[:, ii] / np.diff(np.log(fobs_gw_edges))\n",
    "\n",
    "gwb_resamp_out = np.sqrt(gwb_resamp_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax()\n",
    "xx = fobs_gw * YR\n",
    "ax.plot(xx, gwb_sa, 'k--', lw=1.5, alpha=0.5, label='SA')\n",
    "ax.plot(xx, gwb_fin, 'k:', lw=2.0, alpha=0.5, label='Finite')\n",
    "\n",
    "color = 'b'\n",
    "ax.plot(xx, gwb_mc_med, lw=0.5, color=color)\n",
    "ax.fill_between(xx, *gwb_mc_span, alpha=0.25, color=color, label='MC realized')\n",
    "\n",
    "color = 'r'\n",
    "gwb_resamp_med = np.median(gwb_resamp_out, axis=-1)\n",
    "gwb_resamp_span = np.percentile(gwb_resamp_out, [25, 75], axis=-1)\n",
    "ax.plot(xx, gwb_resamp_med, lw=0.5, color=color, alpha=0.5)\n",
    "ax.fill_between(xx, *gwb_resamp_span, alpha=0.25, color=color, label='Resample')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(yscale='linear', ylabel='Ratio (Resamp/MC)')\n",
    "\n",
    "cc, = ax.plot(xx, gwb_resamp_med/gwb_mc_med, alpha=0.5, label='Median')\n",
    "ax.scatter(xx, gwb_resamp_med/gwb_mc_med, alpha=0.25, color=cc.get_color(), marker='.', s=50)\n",
    "ax.plot(xx, (gwb_resamp_span/gwb_mc_span).T, alpha=0.5, label='Interquartile Boundaries')\n",
    "\n",
    "ax.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fobs_gw = utils.nyquist_freqs(3*YR, 0.1*YR)\n",
    "print(fobs_gw.size)\n",
    "fobs_gw_edges = np.concatenate([fobs_gw - fobs_gw[0]/2, [fobs_gw[-1] + fobs_gw[0]/2]])\n",
    "sam = holo.sam.Semi_Analytic_Model(shape=100)\n",
    "hard = holo.evolution.Hard_GW()\n",
    "gwb_ideal = sam.gwb_ideal(fobs_gw)\n",
    "\n",
    "fig, ax = figax_gwb()\n",
    "print(gwb_ideal[0])\n",
    "xx = fobs_gw*YR\n",
    "ax.plot(xx, gwb_ideal, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use simple versions of GWB calculation here, to use as diagnostics (ground truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam_diff_number_from_ndens(sam, fobs_gw):\n",
    "    const =  (20*np.pi * (SPLC**6)) / 96.0\n",
    "\n",
    "    # `fro` = frst_orb\n",
    "    # (Z, F)\n",
    "    fro_term = fobs_gw[np.newaxis, :] * (1.0 + sam.redz[:, np.newaxis]) / 2.0\n",
    "    fro_term = np.power(2.0*np.pi*fro_term, -8.0/3.0)\n",
    "\n",
    "    # (Z,)\n",
    "    rz_term = sam.redz\n",
    "    rz_term = (cosmo.comoving_distance(rz_term).cgs.value ** 2) * (1.0 + rz_term)\n",
    "\n",
    "    # (M, Q)\n",
    "    mc_term = utils.chirp_mass_mtmr(sam.mtot[:, np.newaxis], sam.mrat[np.newaxis, :])\n",
    "    mc_term = np.power(NWTG * mc_term, -5.0/3.0)\n",
    "    \n",
    "    # d^3 n / [dlog10(M) dq dz] in units of [Mpc^-3]\n",
    "    # (M, Q, Z)\n",
    "    integ = const * sam.static_binary_density / (MPC**3)\n",
    "\n",
    "    # (M, Q, Z)\n",
    "    integ = integ * rz_term[np.newaxis, np.newaxis, :] * mc_term[:, :, np.newaxis]\n",
    "    # (M, Q, Z, F)\n",
    "    integ = integ[:, :, :, np.newaxis] * fro_term[np.newaxis, np.newaxis, :, :]\n",
    "\n",
    "    return integ\n",
    "\n",
    "def sam_gwb_mc(sam, fobs_gw):\n",
    "    number = sam_diff_number_from_ndens(sam, fobs_gw)\n",
    "\n",
    "    # ``frst_orb = fobs_gw * (1+z) / 2``\n",
    "    fro_term = fobs_gw[np.newaxis, :] * (1.0 + sam.redz[:, np.newaxis]) / 2.0\n",
    "    fro_term = np.power(2*np.pi*fro_term, 2.0/3.0) \n",
    "\n",
    "    mc_term = utils.chirp_mass_mtmr(sam.mtot[:, np.newaxis], sam.mrat[np.newaxis, :])\n",
    "    mc_term = np.power(NWTG * mc_term, 5.0/3.0)\n",
    "\n",
    "    dc = cosmo.comoving_distance(sam.redz).cgs.value\n",
    "\n",
    "    hs_const = (8.0 / np.sqrt(10)) / (SPLC**4)\n",
    "    hs_mc = hs_const * mc_term[..., np.newaxis] / dc[np.newaxis, np.newaxis, :]\n",
    "    hs_mc = hs_mc[:, :, :, np.newaxis] * fro_term[np.newaxis, np.newaxis, :, :]\n",
    "    \n",
    "    gwb = utils.trapz(number * (hs_mc**2), np.log10(sam.mtot), axis=0, cumsum=False)        \n",
    "    gwb = utils.trapz(gwb, sam.mrat, axis=1, cumsum=False)\n",
    "    gwb = utils.trapz(gwb, sam.redz, axis=2, cumsum=False)\n",
    "\n",
    "    gwb = np.sqrt(np.sum(gwb, axis=(0, 1, 2)))\n",
    "    return gwb\n",
    "    \n",
    "gwb_mc = sam_gwb_mc(sam, fobs_gw)\n",
    "\n",
    "xx = fobs_gw * YR\n",
    "fig, ax = figax_gwb()\n",
    "ax.plot(xx, gwb_ideal, 'k--', alpha=0.5, label='ideal/SA')\n",
    "ax.plot(xx, gwb_mc, alpha=0.5, label='MC')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam_gwb_mc_real(sam, fobs_gw, fobs_gw_edges):\n",
    "\n",
    "    mt = 0.5 * (sam.mtot[1:] + sam.mtot[:-1])\n",
    "    mr = 0.5 * (sam.mrat[1:] + sam.mrat[:-1])\n",
    "    rz = 0.5 * (sam.redz[1:] + sam.redz[:-1])\n",
    "    \n",
    "    # ``frst_orb = fobs_gw * (1+z) / 2``\n",
    "    fro_term = fobs_gw[np.newaxis, :] * (1.0 + rz[:, np.newaxis]) / 2.0\n",
    "    fro_term = np.power(2*np.pi*fro_term, 2.0/3.0) \n",
    "\n",
    "    mc_term = utils.chirp_mass_mtmr(mt[:, np.newaxis], mr[np.newaxis, :])\n",
    "    mc_term = np.power(NWTG * mc_term, 5.0/3.0)\n",
    "\n",
    "    dc = cosmo.comoving_distance(rz).cgs.value\n",
    "\n",
    "    hs_const = (8.0 / np.sqrt(10)) / (SPLC**4)\n",
    "    hs_mc = hs_const * mc_term[..., np.newaxis] / dc[np.newaxis, np.newaxis, :]\n",
    "    hs_mc = hs_mc[:, :, :, np.newaxis] * fro_term[np.newaxis, np.newaxis, :, :]\n",
    "    \n",
    "    # number = sam_diff_number_from_ndens(sam, fobs_gw_edges)\n",
    "    number = sam_diff_number_from_ndens(sam, fobs_gw)\n",
    "    number = utils.trapz(number, np.log10(sam.mtot), axis=0, cumsum=False)\n",
    "    number = utils.trapz(number, sam.mrat, axis=1, cumsum=False)\n",
    "    number = utils.trapz(number, sam.redz, axis=2, cumsum=False)\n",
    "    # number = utils.trapz(number, np.log(fobs_gw_edges), axis=3, cumsum=False)\n",
    "    number = number * np.diff(np.log(fobs_gw_edges))\n",
    "    # number = np.random.poisson(number)\n",
    "    # number = np.random.poisson(number[..., np.newaxis], size=(number.shape + (30,)))\n",
    "\n",
    "    df = np.diff(fobs_gw_edges)\n",
    "    gwb = (hs_mc**2) * (fobs_gw / df)\n",
    "    # gwb = number * gwb[..., np.newaxis]\n",
    "    gwb = number * gwb\n",
    "    gwb = np.sqrt(np.sum(gwb, axis=(0, 1, 2)))\n",
    "    \n",
    "    return gwb\n",
    "    \n",
    "gwb_mc_real = sam_gwb_mc_real(sam, fobs_gw, fobs_gw_edges)\n",
    "\n",
    "xx = fobs_gw * YR\n",
    "fig, ax = figax_gwb()\n",
    "ax.plot(xx, gwb_ideal, 'k--', alpha=0.5, label='ideal/SA')\n",
    "ax.scatter(xx, gwb_ideal, color='k', s=50, alpha=0.25, marker='+')\n",
    "ax.plot(xx, gwb_mc, alpha=0.75, label='MC', ls=':', lw=3.0)\n",
    "ax.plot(xx, gwb_mc_real, alpha=0.5, label='MC real')\n",
    "ax.legend()\n",
    "\n",
    "tw = ax.twinx()\n",
    "rat = gwb_mc_real / gwb_ideal\n",
    "print(rat)\n",
    "tw.plot(xx, rat, 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare local versions of GWB calculation to `Semi_Analytic_Model` version of the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xx = fobs_gw * YR\n",
    "fig, ax = figax_gwb()\n",
    "ax.plot(xx, gwb_ideal, 'k--', alpha=0.5, label='ideal/SA')\n",
    "ax.scatter(xx, gwb_ideal, color='k', s=50, alpha=0.25, marker='+')\n",
    "ax.plot(xx, gwb_mc, alpha=0.75, label='MC', ls=':', lw=3.0)\n",
    "ax.plot(xx, gwb_mc_real, alpha=0.5, label='MC real', ls='-.', lw=2.0)\n",
    "\n",
    "# gwb_check = sam.gwb(fobs_gw_edges, realize=False, hard=hard)\n",
    "# ax.plot(xx, gwb_check, label='Check', alpha=0.5)\n",
    "\n",
    "gwb_check = sam.gwb(fobs_gw_edges, realize=100)\n",
    "gwb_check_med = np.median(gwb_check, axis=-1)\n",
    "gwb_check_span = np.percentile(gwb_check, [25, 75], axis=-1)\n",
    "col, = ax.plot(xx, gwb_check_med, label='Check')\n",
    "col = col.get_color()\n",
    "ax.fill_between(xx, *gwb_check_span, label='Check', color=col, alpha=0.15)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try `kalepy` resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NREALS = 30\n",
    "\n",
    "shape = (fobs_gw.size, NREALS)\n",
    "\n",
    "gffreq = np.zeros(shape)\n",
    "gwfore = np.zeros(shape)\n",
    "gwback = np.zeros(shape)\n",
    "\n",
    "for ii in utils.tqdm(range(NREALS)):\n",
    "    fobs_orb_edges = fobs_gw_edges / 2.0\n",
    "    # `fobs_orb` is returned in `edges[3]`, and vals[3] is also observer-frame orbital frequencies\n",
    "    vals, weights, edges, dens, mass = holo.sam.sample_sam_with_hardening(sam, hard, fobs_orb=fobs_orb_edges, sample_threshold=1e1, poisson_inside=True, poisson_outside=True)\n",
    "    gffreq[:, ii], gwfore[:, ii], gwback[:, ii] = holo.gravwaves._gws_from_samples(vals, weights, fobs_gw_edges)\n",
    "    \n",
    "gwb_resamp = np.sqrt((gwfore**2) + (gwback**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = fobs_gw * YR\n",
    "\n",
    "fig, ax = figax_gwb()\n",
    "ax.plot(xx, gwb_ideal, 'k--', alpha=0.5, label='ideal/SA')\n",
    "ax.scatter(xx, gwb_ideal, color='k', s=50, alpha=0.25, marker='+')\n",
    "ax.plot(xx, gwb_mc, alpha=0.75, label='MC', ls=':', lw=3.0)\n",
    "ax.plot(xx, gwb_mc_real, alpha=0.5, label='MC real', ls='-.', lw=2.0)\n",
    "# ax.plot(xx, gwb_check, 'r--', label='Check', alpha=0.5)\n",
    "\n",
    "col, = ax.plot(xx, gwb_check_med, color='r')\n",
    "col = col.get_color()\n",
    "ax.fill_between(xx, *gwb_check_span, label='Check', color=col, alpha=0.15)\n",
    "\n",
    "\n",
    "temp_gwb = gwb_resamp\n",
    "col, = ax.plot(xx, np.median(temp_gwb, axis=-1))\n",
    "col = col.get_color()\n",
    "ax.fill_between(xx, *np.percentile(temp_gwb, [25, 75], axis=-1), label='resamp', color=col, alpha=0.15)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
