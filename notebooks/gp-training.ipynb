{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook will walk you through how to set-up a GP from any given bank of spectra. \n",
    "\n",
    "The GPs come from the python package `george` and we \"train\" them using the package `emcee`. \n",
    "\n",
    "Once the GP is trained, we export it as a pickle object to then use with PTA data.\n",
    "\n",
    "**If you are training from scratch, start here**\n",
    "\n",
    "**If you have already trained and want to use the GP model, start at [Testing the GP](#Testing-the-GP)** after importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "import warnings\n",
    "import sys, glob, time, pickle\n",
    "from pprint import pp\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.signal as ssig\n",
    "import scipy.interpolate as interp\n",
    "\n",
    "import scipy.linalg as sl\n",
    "import scipy.special as ss\n",
    "import scipy.constants as sc\n",
    "import scipy.misc as scmisc\n",
    "import scipy.integrate as si\n",
    "import scipy.optimize as opt\n",
    "\n",
    "import george\n",
    "import george.kernels as kernels\n",
    "import emcee, corner\n",
    "\n",
    "import holodeck as holo\n",
    "from holodeck import utils, plot\n",
    "from holodeck.constants import YR\n",
    "import holodeck.gps.gp_utils as gu\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Silence annoying numpy errors\n",
    "np.seterr(divide='ignore', invalid='ignore', over='ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Plotting settings\n",
    "mpl.rc('font', **{'family': 'serif', 'sans-serif': ['Times'], 'size': 15})\n",
    "mpl.rc('lines', solid_capstyle='round')\n",
    "mpl.rc('mathtext', fontset='cm')\n",
    "mpl.style.use('default')   # avoid dark backgrounds from dark theme vscode\n",
    "plt.rcParams.update({'grid.alpha': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.seterr(all='raise')\n",
    "# warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTRA_FILE_NAME = (\n",
    "    \"/Users/lzkelley/programs/nanograv/15yr_astro_libraries/\"\n",
    "    \"2par_wider/sam_lib.hdf5\"\n",
    ")\n",
    "\n",
    "NFREQS = 5\n",
    "TEST_FRAC = 0.01\n",
    "BURN_FRAC = 0.2\n",
    "NWALKERS = 20\n",
    "NSAMPLES = 1000\n",
    "MPI = False\n",
    "CENTER_MEASURE = \"median\"\n",
    "KERNEL_TYPE = \"ExpSquaredKernel\"\n",
    "KERNEL_OPTS = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spectra\n",
    "\n",
    "    The first step is to load the bank of spectra. \n",
    "    Make sure to double check that dimensionality of the parameter space, and get the parameter limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Spectra from Luke\n",
    "spectra_file = Path(SPECTRA_FILE_NAME)\n",
    "spectra = h5py.File(spectra_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spectra.keys()))\n",
    "param_names = spectra.attrs['param_names'].astype(str)\n",
    "sample_params = spectra['sample_params']\n",
    "print(param_names)\n",
    "print(sample_params.shape)\n",
    "\n",
    "gwb = spectra['gwb']\n",
    "print(gwb.shape)\n",
    "if np.count_nonzero(gwb) / gwb.size < 0.5:\n",
    "    raise RuntimeError(f\"Fraction of gwb > 0.0 :: {utils.frac_str(gwb[()] > 0.0)}\")\n",
    "\n",
    "print(spectra['fobs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, key in enumerate(param_names):\n",
    "    vals = sample_params[:, ii]\n",
    "    print(f\"{key:>20s} (min, max) = ({vals.min():+.2e}, {vals.max():+.2e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = spectra['fobs'][()] * YR\n",
    "gwb = spectra['gwb']\n",
    "nsamp = gwb.shape[0]\n",
    "fig, ax = plot.figax()\n",
    "for ii in np.random.choice(nsamp, size=10, replace=False):\n",
    "    yy = gwb[ii, :, :]\n",
    "    plot.draw_med_conf(ax, xx, yy)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth the GWB Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_freqs, xobs, yerr, yobs, yobs_mean = gu.get_smoothed_gwb(\n",
    "    spectra, NFREQS, TEST_FRAC, CENTER_MEASURE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(scale='lin')\n",
    "nsamp = yobs.shape[0]\n",
    "xx = gp_freqs\n",
    "for ii in np.random.choice(nsamp, size=10, replace=False):\n",
    "    ave = yobs[ii, :]\n",
    "    cc, = ax.plot(xx, ave, alpha=0.75)\n",
    "    cc = cc.get_color()\n",
    "    for conf in [1.0, 2.0]:\n",
    "        hi = ave + yerr[ii, :] / conf\n",
    "        lo = ave - yerr[ii, :] / conf\n",
    "        ax.fill_between(xx, lo, hi, alpha=0.2, color=cc)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct GP kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holodeck as holo\n",
    "for ii, par in enumerate(param_names):\n",
    "    print(ii, par, xobs[:, ii].min(), xobs[:, ii].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = george.kernels.ExpSquaredKernel(1.0e2)\n",
    "# gp = george.GP(kernel)\n",
    "# fig, ax = plt.subplots()\n",
    "# t = np.linspace(0.0, 10.0, 100)\n",
    "# ns = 10\n",
    "# zz = 0.0\n",
    "\n",
    "# for yy in gp.sample(t, ns):\n",
    "#     ax.plot(t, yy)\n",
    "#     zz += np.count_nonzero(np.diff(np.sign(yy)))\n",
    "\n",
    "# print(zz/ns)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_george, num_kpars = gu.create_gp_kernels(\n",
    "    gp_freqs, param_names, xobs, yerr, yobs, KERNEL_TYPE, KERNEL_OPTS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GP (fit kernel parameters to smoothed spectra at each frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu.fit_kernel_params(\n",
    "    gp_freqs, yobs_mean, gp_george, num_kpars, NWALKERS, NSAMPLES, BURN_FRAC, MPI,\n",
    "    sample_kwargs=dict(skip_initial_state_check=True)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gp_george[0]\n",
    "print(gp.emcee_flatchain.shape)\n",
    "fig, axes = plot.figax(nrows=3, scale='lin')\n",
    "zz = gp.emcee_flatlnprob\n",
    "smap = plot.smap(zz, cmap='Spectral')\n",
    "colors = smap.to_rgba(zz)\n",
    "for ii, ax in enumerate(axes):\n",
    "    yy = gp.emcee_flatchain[:, ii]\n",
    "    ax.scatter(1+np.arange(yy.size), yy, facecolor=colors, edgecolor='0.25', lw=0.1, alpha=0.25, s=5)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gp_george[0]\n",
    "print(gp.emcee_flatchain.shape)\n",
    "# import kalepy as kale\n",
    "# kale.corner(gp.emcee_flatchain.T)\n",
    "# gp.emcee_kernel_map\n",
    "fig, axes = plot.figax(nrows=3, scale='lin')\n",
    "zz = gp.emcee_flatlnprob\n",
    "print(zz.shape, utils.stats(zz))\n",
    "smap = plot.smap([0.0, 1.0], cmap='Spectral')\n",
    "colors = smap.to_rgba(np.linspace(0.0, 1.0, zz.size))\n",
    "for ii, ax in enumerate(axes):\n",
    "    xx = gp.emcee_flatchain[:, ii]\n",
    "    ax.scatter(xx, zz, c=colors, s=3, alpha=0.2)\n",
    "\n",
    "cax = fig.add_axes([0.95, 0.2, 0.02, 0.6])\n",
    "plt.colorbar(smap, cax=cax)    \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = gu.set_up_predictions(gp_george)\n",
    "mean_pars = gu.mean_par_dict(gp_george)\n",
    "pp(gp_george[0].par_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpg = gp_george[0]\n",
    "gpg.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freqs = len(gps)\n",
    "print(f\"{num_freqs=}\")\n",
    "# mp = list(mean_pars.values())\n",
    "# print(mp)\n",
    "\n",
    "# pars = mp\n",
    "nsamp = gp_george[0].y.size\n",
    "idx = np.random.choice(nsamp)\n",
    "print(f\"{idx=}\")\n",
    "\n",
    "pars = spectra['sample_params'][idx, :]\n",
    "\n",
    "print(pars)\n",
    "xx = spectra['fobs'][:num_freqs]\n",
    "\n",
    "hc, rho, rho_pred = gu.hc_from_gp(gp_george, gps, pars)\n",
    "print(hc)\n",
    "\n",
    "fig, ax = plot.figax()\n",
    "\n",
    "ax.plot(xx, hc)\n",
    "\n",
    "gwb = spectra['gwb'][idx]\n",
    "print(gwb.shape)\n",
    "gwb = gwb[:num_freqs, :]\n",
    "print(gwb.shape)\n",
    "med = np.median(gwb, axis=-1)\n",
    "print(med)\n",
    "\n",
    "cc, = ax.plot(xx, med)\n",
    "cc = cc.get_color()\n",
    "ax.fill_between(xx, *np.percentile(gwb, [25, 75], axis=-1), alpha=0.2, color=cc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLDER METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the mean and std from all spectra realizations\n",
    "    At each point in parameter space, we need to find the mean value and the standard deviation from all of the realizations that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE - Only need to train GP on number of frequencies in PTA analysis !\n",
    "gwb_spectra = spectra['gwb'][:,:30,:]**2\n",
    "\n",
    "# Find all of the zeros and set them to be h_c = 1e-20\n",
    "low_ind = np.where(gwb_spectra < 1e-40)\n",
    "gwb_spectra[low_ind] = 1e-40\n",
    "\n",
    "\n",
    "# Find mean over 100 realizations\n",
    "mean = np.log10(np.mean(gwb_spectra, axis=-1))\n",
    "\n",
    "# Smooth Mean Spectra\n",
    "## NOTE FOR LUKE - HOW MUCH SMOOTHING DO WE WANT TO DO ?\n",
    "smooth_mean = ssig.savgol_filter(mean, 7, 3)\n",
    "\n",
    "# Find std\n",
    "err = np.std(np.log10(gwb_spectra), axis=-1)\n",
    "\n",
    "if np.any(np.isnan(err)):\n",
    "    print('Got a NAN issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is an example plot of the smoothed mean, the mean and standard deviation\n",
    "## and all of the spectra realizations, for a random point in parameter space.\n",
    "\n",
    "# Choose a gwb\n",
    "ind = 0\n",
    "\n",
    "for ii in range(spectra['gwb'].shape[-1]):\n",
    "    plt.loglog(spectra['fobs'][:30]*YR, spectra['gwb'][ind,:30,ii]**2, color='C0', alpha=0.3, zorder=0)\n",
    "plt.loglog(spectra['fobs'][:30]*YR, spectra['gwb'][ind,:30,0]**2, color='C0', alpha=0.3, zorder=0, label='50 Spectra')\n",
    "plt.loglog(spectra['fobs'][:30]*YR, 10**mean[ind], color='C1', label='Mean')\n",
    "plt.loglog(spectra['fobs'][:30]*YR, 10**smooth_mean[ind], color='C3', label='Smoothed Mean')\n",
    "plt.fill_between(spectra['fobs'][:30]*YR, 10**(mean[ind]-err[ind]), 10**(mean[ind]+err[ind]), color='C1', alpha=0.5)\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(r'GW Frequency [yr$^{-1}$]')\n",
    "plt.ylabel(r'$h_{c}^{2}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.array(spectra['fobs'])[:30]*YR).max())\n",
    "print((np.array(spectra['fobs'])*YR).min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GP\n",
    "\n",
    "    The next step is to set up the GP class.\n",
    "    Things to note:\n",
    "        - need to make sure that the GP has the same dimensionality as the parameter space from the spectra.\n",
    "        - the GPs work better when they are trained on zero-mean data, so it's very important that we remove the mean values for the spectra at each frequency, BUT these values HAVE TO BE SAVED, because they are required to extract meaningful information back out of the GP once it is trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a GP class containing the kernel parameter priors and a log-likelihood\n",
    "\n",
    "class gaussproc(object):\n",
    "    \n",
    "    def __init__(self, x, y, yerr=None, par_dict = None):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yerr = yerr\n",
    "        self.par_dict = par_dict\n",
    "        \n",
    "        # The number of GP parameters is one more than the number of spectra parameters.\n",
    "        self.pmax = np.array([20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]) # sampling ranges\n",
    "        self.pmin = np.array([-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0])\n",
    "        self.emcee_flatchain = None\n",
    "        self.emcee_flatlnprob = None\n",
    "        self.emcee_kernel_map = None\n",
    "    \n",
    "    def lnprior(self, p):\n",
    "    \n",
    "        logp = 0.\n",
    "    \n",
    "        if np.all(p <= self.pmax) and np.all(p >= self.pmin):\n",
    "            logp = np.sum(np.log(1/(self.pmax-self.pmin)))\n",
    "        else:\n",
    "            logp = -np.inf\n",
    "\n",
    "        return logp\n",
    "\n",
    "    def lnlike(self, p):\n",
    "\n",
    "        # Update the kernel and compute the lnlikelihood.\n",
    "        a, tau = np.exp(p[0]), np.exp(p[1:])\n",
    "        \n",
    "        lnlike = 0.0\n",
    "        try:\n",
    "            gp = george.GP(a * kernels.ExpSquaredKernel(tau,ndim=len(tau)))\n",
    "            #gp = george.GP(a * kernels.Matern32Kernel(tau))\n",
    "            gp.compute(self.x , self.yerr)\n",
    "            \n",
    "            lnlike = gp.lnlikelihood(self.y, quiet=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            lnlike = -np.inf\n",
    "        \n",
    "        return lnlike\n",
    "    \n",
    "    def lnprob(self, p):\n",
    "        \n",
    "        return self.lnprior(p) + self.lnlike(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the spectra data!\n",
    "\n",
    "# The \"y\" data are the means and errors for the spectra at each point in parameter space\n",
    "yobs = smooth_mean.copy() #mean.copy()\n",
    "yerr = err.copy()\n",
    "GP_freqs = spectra['fobs'][:30].copy()\n",
    "GP_freqs *= YR\n",
    "\n",
    "## Find mean in each frequency bin (remove it before analyzing with the GP) ##\n",
    "# This allows the GPs to oscillate around zero, where they are better behaved.\n",
    "yobs_mean = np.mean(yobs,axis=0)\n",
    "# MAKE SURE TO SAVE THESE VALUES - THE GP IS USELESS WITHOUT THEM !\n",
    "np.save('./Luke_Spectra_MEANS.npy', yobs_mean)\n",
    "\n",
    "yobs -= yobs_mean[None,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on saving the means\n",
    "I think that this .npy file is not needed, the means are saved as an attribute of the `gaussproc` objects in the `gp_george` list [here](#Save-training-information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pars = spectra['parameters'].attrs['ordered_parameters']\n",
    "\n",
    "## The \"x\" data are the actual parameter values\n",
    "xobs = np.zeros((spectra['gwb'].shape[0], len(pars)))\n",
    "\n",
    "# [gsmf_phi0, hard_gamma_inner, hard_gamma_outer, hard_rchar, hard_time, mmb_amp]\n",
    "for ii in range((spectra['gwb'].shape[0])):\n",
    "    for k, par in enumerate(pars):\n",
    "        xobs[ii,k] = spectra['sample_params'][ii,k]\n",
    "        \n",
    "# Put mmb_amp in logspace\n",
    "xobs[:, -1] = np.log10(xobs[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate a list of GP kernels and models [one for each frequency]\n",
    "\n",
    "gp_george = []\n",
    "k = []\n",
    "\n",
    "# Create the parameter dictionary for the gp objects\n",
    "par_dict = dict()\n",
    "for ind, par in enumerate(pars):\n",
    "    par_dict[par] = {\"min\": np.min(xobs[:, ind]),\n",
    "                     \"max\": np.max(xobs[:, ind])}\n",
    "    \n",
    "for freq_ind in range(len(GP_freqs)):\n",
    "    \n",
    "    gp_george.append(gaussproc(xobs,yobs[:,freq_ind],yerr[:,freq_ind], par_dict))\n",
    "    k.append( 1.0 * kernels.ExpSquaredKernel([2.0,2.0,2.0,2.0,2.0,2.0],ndim=6) )\n",
    "    num_kpars = len(k[freq_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample the posterior distribution of the kernel parameters \n",
    "# to find MAP value for each frequency. \n",
    "\n",
    "# THIS WILL TAKE A WHILE... (~ 5 min per frequency on 18 cores)\n",
    "\n",
    "sampler = [0.0]*len(GP_freqs)\n",
    "nwalkers, ndim = 36, num_kpars\n",
    "for freq_ind in range(len(GP_freqs)):\n",
    "    # Parellize emcee with nwalkers //2 or the maximum number of processors available, whichever is smaller\n",
    "    with Pool(min(nwalkers // 2, cpu_count()) ) as pool:\n",
    "        t_start = time.time()\n",
    "\n",
    "        # Set up the sampler.\n",
    "        sampler[freq_ind] = emcee.EnsembleSampler(nwalkers, ndim, gp_george[freq_ind].lnprob, pool=pool)\n",
    "\n",
    "        # Initialize the walkers.\n",
    "        p0 = [np.log([1.,1.,1.,1.,1.,1., 1.]) + 1e-4 * np.random.randn(ndim)\n",
    "              for i in range(nwalkers)]\n",
    "\n",
    "        print(freq_ind, \"Running burn-in\")\n",
    "        p0, lnp, _ = sampler[freq_ind].run_mcmc(p0, int(750))\n",
    "        sampler[freq_ind].reset()\n",
    "\n",
    "        print(freq_ind, \"Running second burn-in\")\n",
    "        p = p0[np.argmax(lnp)]\n",
    "        p0 = [p + 1e-8 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "        p0, _, _ = sampler[freq_ind].run_mcmc(p0, int(750))\n",
    "        sampler[freq_ind].reset()\n",
    "\n",
    "        print(freq_ind, \"Running production\")\n",
    "        p0, _, _ = sampler[freq_ind].run_mcmc(p0, int(1500))\n",
    "\n",
    "        print('Completed in {} min'.format((time.time()-t_start)/60.) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Let's take a look at the posterior distribution of the \n",
    "# kernel parameters at a frequency [ind] of our choice.\n",
    "\n",
    "ind = 0\n",
    "\n",
    "fig = corner.corner(sampler[ind].flatchain,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save training information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Populate the GP class with the details of the kernel \n",
    "## MAP values for each frequency.\n",
    "\n",
    "for ii in range(len(GP_freqs)):\n",
    "    \n",
    "    gp_george[ii].chain = None \n",
    "    gp_george[ii].lnprob = None \n",
    "    \n",
    "    gp_george[ii].kernel_map = sampler[ii].flatchain[np.argmax(sampler[ii].flatlnprobability)] \n",
    "    #print(ii, gp_george[ii].kernel_map)\n",
    "    \n",
    "    # add-in mean yobs (freq) values\n",
    "    gp_george[ii].mean_spectra = yobs_mean[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the trained GP as a pickle to be used with PTA data!\n",
    "gp_file = \"trained_gp_\" + spectra_file.stem + \".pkl\"\n",
    "with open(gp_file, \"wb\") as gpf:\n",
    "    pickle.dump(gp_george, gpf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the GP\n",
    "    The following is some example code looking at how to extract predictions from the GP and test it against the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Spectra from library\n",
    "# Modify this as necessary for your library\n",
    "spectra_file = Path('./spec_libraries/hard04b_n1000_g100_s40_r50_f40/sam-lib_hard04b_2023-01-23_01_n1000_g100_s40_r50_f40.hdf5')\n",
    "spectra = h5py.File(spectra_file, 'r')\n",
    "\n",
    "gwb_spectra = spectra['gwb'][:,:30,:]**2\n",
    "\n",
    "# Find all of the zeros and set them to be h_c = 1e-20\n",
    "low_ind = np.where(gwb_spectra < 1e-40)\n",
    "gwb_spectra[low_ind] = 1e-40\n",
    "\n",
    "\n",
    "# Find mean over 100 realizations\n",
    "mean = np.log10(np.mean(gwb_spectra, axis=-1))\n",
    "\n",
    "# Smooth Mean Spectra\n",
    "## NOTE FOR LUKE - HOW MUCH SMOOTHING DO WE WANT TO DO ?\n",
    "smooth_mean = ssig.savgol_filter(mean, 7, 3)\n",
    "\n",
    "# Find std\n",
    "err = np.std(np.log10(gwb_spectra), axis=-1)\n",
    "\n",
    "if np.any(np.isnan(err)):\n",
    "    print('Got a NAN issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a GP class containing the kernel parameter priors and a log-likelihood\n",
    "\n",
    "class gaussproc(object):\n",
    "    \n",
    "    def __init__(self, x, y, yerr=None, par_dict = None):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yerr = yerr\n",
    "        self.par_dict = par_dict\n",
    "        \n",
    "        # The number of GP parameters is one more than the number of spectra parameters.\n",
    "        self.pmax = np.array([20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]) # sampling ranges\n",
    "        self.pmin = np.array([-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0])\n",
    "        self.emcee_flatchain = None\n",
    "        self.emcee_flatlnprob = None\n",
    "        self.emcee_kernel_map = None\n",
    "    \n",
    "    def lnprior(self, p):\n",
    "    \n",
    "        logp = 0.\n",
    "    \n",
    "        if np.all(p <= self.pmax) and np.all(p >= self.pmin):\n",
    "            logp = np.sum(np.log(1/(self.pmax-self.pmin)))\n",
    "        else:\n",
    "            logp = -np.inf\n",
    "\n",
    "        return logp\n",
    "\n",
    "    def lnlike(self, p):\n",
    "\n",
    "        # Update the kernel and compute the lnlikelihood.\n",
    "        a, tau = np.exp(p[0]), np.exp(p[1:])\n",
    "        \n",
    "        lnlike = 0.0\n",
    "        try:\n",
    "            gp = george.GP(a * kernels.ExpSquaredKernel(tau,ndim=len(tau)))\n",
    "            #gp = george.GP(a * kernels.Matern32Kernel(tau))\n",
    "            gp.compute(self.x , self.yerr)\n",
    "            \n",
    "            lnlike = gp.lnlikelihood(self.y, quiet=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            lnlike = -np.inf\n",
    "        \n",
    "        return lnlike\n",
    "    \n",
    "    def lnprob(self, p):\n",
    "        \n",
    "        return self.lnprior(p) + self.lnlike(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_file = \"trained_gp_\" + spectra_file.stem + \".pkl\"\n",
    "with open( gp_file, \"rb\") as f:\n",
    "    gp_george = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set-up GP predictions ##\n",
    "\n",
    "gp = []\n",
    "GP_freqs = spectra['fobs'][:30].copy()\n",
    "\n",
    "for ii in range(len(GP_freqs)):\n",
    "    gp_kparams = np.exp(gp_george[ii].kernel_map)\n",
    "\n",
    "    gp.append(george.GP(gp_kparams[0] * \\\n",
    "            george.kernels.ExpSquaredKernel(gp_kparams[1:],ndim=len(gp_kparams[1:])) ) )\n",
    "\n",
    "    gp[ii].compute(gp_george[ii].x, gp_george[ii].yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameter pairs\n",
    "pars = list(gp_george[0].par_dict.keys()) # dictionaries since 3.6 keep their order! Nice\n",
    "\n",
    "## The \"x\" data are the actual parameter values\n",
    "xobs = np.zeros((spectra['gwb'].shape[0], len(pars)))\n",
    "\n",
    "# [gsmf_phi0, hard_gamma_inner, hard_gamma_outer, hard_rchar, hard_time, mmb_amp]\n",
    "for ii in range((spectra['gwb'].shape[0])):\n",
    "    for k, par in enumerate(pars):\n",
    "        xobs[ii,k] = spectra['sample_params'][ii,k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a realization from the GP\n",
    "\n",
    "A reminder of the spectra parameters:\n",
    "|Parameter|(min, max)|\n",
    "| --- | --- |\n",
    "|gsmf_phi0 |(-3.00e+00, -2.00e+00)|\n",
    "|hard_gamma_inner | (-1.50e+00, -5.00e-01)\n",
    "|hard_gamma_outer | (2.00e+00, 3.00e+00)\n",
    "|hard_rchar | (1.00e+00, 3.00e+00)\n",
    "|hard_time | (-1.00e+00, 1.00e+00)\n",
    "|mmb_amp | (1.00e+08, 1.00e+09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the background to look at out of the 1,000 available\n",
    "ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_param = xobs[ind,:].copy()\n",
    "# Convert to log10(mmb_amp)\n",
    "env_param[-1]= np.log10(env_param[-1])\n",
    "\n",
    "rho_pred = np.zeros((len(GP_freqs),2))\n",
    "for ii,freq in enumerate(GP_freqs):\n",
    "    mu_pred, cov_pred = gp[ii].predict(gp_george[ii].y, [env_param])\n",
    "    if np.diag(cov_pred) < 0.0:\n",
    "        rho_pred[ii,0], rho_pred[ii,1] = mu_pred, 1e-5 * mu_pred\n",
    "    else:\n",
    "        rho_pred[ii,0], rho_pred[ii,1] = mu_pred, np.sqrt(np.diag(cov_pred))\n",
    "\n",
    "## transforming from zero-mean unit-variance variable to rho\n",
    "rho = np.array([gp_george[ii].mean_spectra for ii in range(len(GP_freqs))]) + rho_pred[:,0]\n",
    "\n",
    "hc = np.sqrt(10**rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a plot ##\n",
    "\n",
    "# the raw spectra #\n",
    "for ii in range(spectra['gwb'].shape[-1]):\n",
    "    plt.loglog(spectra['fobs'][:30], spectra['gwb'][ind,:30,ii], color='C0', alpha=0.2, zorder=0)\n",
    "plt.loglog(spectra['fobs'][:30], spectra['gwb'][ind,:30,ii], color='C0', alpha=0.2, zorder=0, label='Original Spectra')\n",
    "\n",
    "# the smoothed mean #\n",
    "plt.loglog(spectra['fobs'][:30], np.sqrt(10**smooth_mean[ind]), color='C1', label='Smoothed Mean', lw=2)\n",
    "\n",
    "# the GP realization #\n",
    "plt.semilogx(GP_freqs, hc, color='C3', lw=2.5, label='GP')\n",
    "plt.fill_between(GP_freqs, np.sqrt(10**(rho+rho_pred[:,1])), np.sqrt(10**(rho-rho_pred[:,1])), color='C3', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.xlabel('Observed GW Frequency [Hz]')\n",
    "#plt.xlim(1e-9,7e-8)\n",
    "plt.ylabel(r'$h_{c} (f)$')\n",
    "#plt.ylim(1e-16, 1e-13)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "#plt.savefig('./TrainedGP.pdf', bbox_inches='tight', dpi=500)\n",
    "\n",
    "# Print the parameter values for this gwb\n",
    "for i, par in enumerate(xobs[ind,:]):\n",
    "    print(f\"{pars[i]} = {xobs[ind,i]:.2E}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f0c7602c82e39efa19a01e5e068584db7a6d17aff8711ab06660aac81377393"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
