{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import scipy as sp\n",
    "\n",
    "import holodeck as holo\n",
    "import holodeck.single_sources as ss\n",
    "import holodeck.detstats as det\n",
    "from holodeck.constants import YR, MSOL\n",
    "from holodeck import utils\n",
    "\n",
    "\n",
    "import hasasia.sensitivity as hsen\n",
    "import hasasia.sim as hsim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build SAM and calculate strains"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the semi-analytic model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = 10.0*YR\n",
    "cad = 0.2*YR\n",
    "fobs = utils.nyquist_freqs(dur,cad)\n",
    "fobs_edges = utils.nyquist_freqs_edges(dur,cad)\n",
    "sam = holo.sam.Semi_Analytic_Model(ZERO_GMT_STALLED_SYSTEMS=True, ZERO_DYNAMIC_STALLED_SYSTEMS=False) \n",
    "# sam = holo.sam.Semi_Analytic_Model(mtot=(1.0e4*MSOL, 1.0e11*MSOL, 20), mrat=(1e-3, 1.0, 20), redz=(1e-3, 10.0, 20))  # faster version\n",
    "hard = holo.hardening.Hard_GW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fobs_orb_edges = fobs_edges / 2.0 \n",
    "fobs_orb_cents = fobs/ 2.0\n",
    "# edges\n",
    "edges, dnum = sam.dynamic_binary_number(hard, fobs_orb=fobs_orb_cents) # should the zero stalled option be part of the parameter space?\n",
    "edges[-1] = fobs_orb_edges\n",
    "# integrate for number\n",
    "number = utils._integrate_grid_differential_number(edges, dnum, freq=False)\n",
    "number = number * np.diff(np.log(fobs_edges)) \n",
    "hc_ss, hc_bg = ss.ss_gws(edges, number, realize=30, \n",
    "                                        loudest = 1, params = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreals = np.min([10, len(hc_bg[0])])\n",
    "colors = cm.rainbow(np.linspace(0,1,nreals))\n",
    "plt.xlabel('Frequency, $f_\\mathrm{obs}$ (1/yr)')\n",
    "plt.ylabel('Characteristic Strain, $h_c$')\n",
    "for rr in range(nreals):\n",
    "    if(rr==0):\n",
    "        label_bg = 'GWB'\n",
    "        label_ss = 'SS'\n",
    "    else:\n",
    "        label_bg = None\n",
    "        label_ss = None\n",
    "    plt.loglog(fobs*YR, hc_bg[:,rr], alpha=0.5, label=label_bg)\n",
    "    plt.scatter(fobs*YR, hc_ss[:,rr,0], alpha=0.5, label=label_ss)\n",
    "plt.loglog(fobs*YR, np.median(hc_bg, axis=1), color='k')\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build pulsar timing array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place pulsars at random positions with random white noise, and create a list of hasasia.sensitivity.Pulsar objects with hasasia.sim.sim_pta.\n",
    "A single PTA is created and used to calculate detection statistics on many realizations of GW sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npsrs = 40\n",
    "phis = np.random.uniform(0, 2*np.pi, size=npsrs)\n",
    "thetas = np.random.uniform(0, np.pi, size=npsrs)\n",
    "sigmas = np.random.uniform(1e-7, 4e-6, npsrs)\n",
    "\n",
    "pulsars = hsim.sim_pta(timespan=dur/YR, cad=1/(cad/YR), sigma=sigmas,\n",
    "                       phi=phis, theta=thetas)\n",
    "print(pulsars[0].__dict__.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a spectrum for each pulsar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = np.empty_like(pulsars, dtype=hsen.Spectrum)\n",
    "for ii in range(npsrs):\n",
    "    spectra[ii] = hsen.Spectrum(pulsars[ii], freqs=fobs)\n",
    "    spectra[ii].NcalInv # calculate inverse noise weighted transmission function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a plot of the pulsar locations\n",
    "plt.xlabel(r'$\\theta/\\pi$')\n",
    "plt.ylabel(r'$\\phi/\\pi$ ')\n",
    "plt.scatter(thetas/np.pi, phis/np.pi, marker='*', s=40,\n",
    "            c=sigmas, cmap='viridis')\n",
    "plt.colorbar(label='$\\sigma$ (s)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it's background sensitivity curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scGWB = hsen.GWBSensitivityCurve(list(spectra))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate background detection probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list of hasasia.sensitivity.Pulsar objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = det.detect_bg_pta(pulsars, spectra, cad, hc_bg)\n",
    "print('Detection probability of the background in each realization:\\,',dp)\n",
    "plt.hist(dp)\n",
    "plt.xlabel('BG Detection Probability $\\gamma_\\mathrm{bg}$')\n",
    "plt.ylabel('Number of Realizations')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stored arrays, should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp2 = det.detect_bg(thetas, phis, sigmas, fobs, cad, hc_bg)\n",
    "plt.hist(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate calculations \n",
    "These all follow equations from Rosado et al. 2015, and are calculated within the detect_bg and detect_bg_pta functions, returned if ret_all=True."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap reduction function \n",
    "$$ \\Gamma_{ij} = \\frac{3}{2} \\gamma_{ij} \\ln (\\gamma_{ij}) - \\frac{1}{4} \\gamma_{ij} + \\frac{1}{2} + \\frac{1}{2}\\delta_{ij} \\quad\\quad(24)$$\n",
    "$$ \\gamma_{ij} = [1-\\cos (\\theta_{ij})]/2$$\n",
    "\n",
    "Can be calculated using the list of pulsars, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma = det._orf_pta(pulsars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or directly for each pair of pulsars' angles. They should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma2 = np.zeros((npsrs, npsrs))\n",
    "for ii in range(npsrs):\n",
    "    for jj in range(npsrs):\n",
    "        if (jj>ii): # 0 otherwise, allows sum over all\n",
    "            # calculate angle between two vectors.\n",
    "            theta_ij =  det._relative_angle(pulsars[ii].theta, pulsars[ii].phi,\n",
    "                                        pulsars[jj].theta, pulsars[jj].phi)\n",
    "            # find ORF\n",
    "            Gamma2[ii,jj] = det._orf_ij(ii, jj, theta_ij)\n",
    "\n",
    "assert(np.all(Gamma==Gamma2)), 'Gamma calculation is failing!'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulsar noise spectral density, $P_i$\n",
    "$$ P_i = 2 \\Delta t \\sigma_i^2 \\quad\\quad(23)$$\n",
    "Currently, this only accounts for white noise, but it allows for different sigma values for each pulsar. The sigma values are given by the mean of the toaerrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = det._white_noise(cad, sigmas)\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(sigmas)\n",
    "plt.xlabel('Noise spectral density, $P_i$')\n",
    "plt.ylabel('Number of pulsars')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectral Density\n",
    "$S_h$, the one-sided power spectral density of the GW signal in the timing residuals\n",
    "$$ S_h = \\frac{h_c^2}{12 \\pi ^2 f_k^3} \\quad \\quad(25)$$\n",
    "Let's demonstrate with the first realization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sh_bg = det._power_spectral_density(hc_bg, fobs)\n",
    "print(Sh_bg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.xlabel('Frequency, $f_\\mathrm{obs}$ (Hz)')\n",
    "plt.ylabel('Power Spectral Density, $S_h$ (s$^3$)')\n",
    "plt.loglog(fobs, Sh_bg, alpha=0.5)\n",
    "plt.loglog(fobs, np.median(Sh_bg, axis=1), linewidth=1, color='k')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S_{h0}$ is the **expected** one-sided power spectral density of the GW signal, given by Eq. (26), \n",
    "$$S_{h0} = \\frac{\\cal{A}\\mathrm{yr}^{-4/3}}{12\\pi^2} f^{-13/3}$$\n",
    " where $\\cal{A}$ would be a fiducial characteristic strain amplitude such that $h_c=\\cal{A}[f/\\mathrm{yr}^{-1}]^{-2/3}$.\n",
    "However, Rosado et al. (2019) find justify setting $S_{h0}=S_h$ so we use that approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sh0_bg = Sh_bg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distribution Function\n",
    "We calculate $\\sigma_0$, $\\sigma_1$, and $\\mu_1$, which describe the mean-zero ($\\mu_0=0$) PDF in the absence of a GWB, \n",
    "$$ p_0(S) = \\frac{1}{\\sqrt{2\\pi\\sigma_0^2} }e^{-\\frac{(S-\\mu_0)^2}{2\\sigma_0^2}} $$\n",
    "and the PDF in the presence of a GWB, \n",
    " $$ p_1(S) = \\frac{1}{\\sqrt{2\\pi\\sigma_1^2} }e^{-\\frac{(S-\\mu_1)^2}{2\\sigma_1^2}} $$\n",
    "using\n",
    "$$ \\sigma_0^2 = 2\\sum_f \\sum_{ij} \\frac{\\Gamma_{ij}^2 S_{h0}^2 P_i P_j  }{\\big[ [P_i + S_{h0}] [P_j +S_{h0}] + \\Gamma_{ij}^2 S_{h0}^2  \\big]^2  } \\quad\\quad (A17)$$\n",
    "$$\\mu_1 = 1\\sum_f \\sum_{ij} \\frac{\\Gamma_{ij}^2 S_h S_{h0}}{[P_i + S_{h0}] [P_j + S_{h0}] + \\Gamma_{ij}^2 S_{h0}^2} \\quad\\quad (A16) $$\n",
    "\n",
    "$$ \\sigma_1^2 = 2 \\sum_f \\sum_{ij} \\frac{\\Gamma_{ij}^2 S_{h0}^2 \\big[ [P_i + S_h] [P_j + S_h] + \\Gamma_{ij}^2 S_h^2   \\big]  }{\\big[[P_i + S_{h0}][P_j + S_{h0}] + \\Gamma_{ij}^2 S_{h0}^2  \\big]^2  } \\quad\\quad (A18)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_1B = det._mean1_Bstatistic(noise, Gamma, Sh_bg, Sh0_bg)\n",
    "\n",
    "sigma_0B = det._sigma0_Bstatistic(noise, Gamma, Sh0_bg)\n",
    "\n",
    "sigma_1B = det._sigma1_Bstatistic(noise, Gamma, Sh_bg, Sh0_bg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreals = len(sigma_0B)\n",
    "xarr = np.linspace(-3*np.max(sigma_0B),np.max(mu_1B)+3*np.max(sigma_1B),100)\n",
    "pdf0 = np.zeros((len(xarr), nreals))\n",
    "pdf1 = np.zeros((len(xarr), nreals))\n",
    "\n",
    "\n",
    "colors= cm.rainbow(-np.linspace(0,1,nreals))\n",
    "plt.xlabel('Cross Correlation, $S$')\n",
    "plt.ylabel('PDF, $p(S)$')\n",
    "for rr in range(nreals):\n",
    "    pdf0[:,rr] = sp.stats.norm.pdf(xarr, 0, sigma_0B[rr])\n",
    "    pdf1[:,rr] = sp.stats.norm.pdf(xarr, mu_1B[rr], sigma_1B[rr])\n",
    "    if(rr==0):\n",
    "        label0='null'\n",
    "        label1='GWB'\n",
    "    else:\n",
    "        label0=None\n",
    "        label1=None\n",
    "    plt.plot(xarr, pdf0[:,rr], label=label0, linestyle='dashed', \n",
    "             color=colors[rr], alpha=0.5)\n",
    "    plt.plot(xarr, pdf1[:,rr], label=label1, linestyle='solid',\n",
    "             color=colors[rr], alpha=0.5)\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Probability\n",
    "We now have all the parameters necessary to calculate the background detection probability, $\\gamma_\\mathrm{bg}$, using\n",
    "\n",
    "$$ \\gamma_{bg} = \\frac{1}{2} \\mathrm{erfc} \\big[ \\frac{\\sqrt{2} \\sigma_0 \\mathrm{erfc}^{-1}(2\\alpha_0) - \\mu_1}{\\sqrt{2} \\sigma_1}\\big] \\quad\\quad(15)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_bg = det._bg_detection_probability(sigma_0B, sigma_1B, mu_1B)\n",
    "plt.hist(gamma_bg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check SNR consistency\n",
    "### $\\mathrm{S/N_B}(\\Gamma, S_h, P)$ Comparison\n",
    "There is a function that calculates the B-statistic GWB signal-to-noise ratio, $\\mathrm{S/N}_B\\equiv \\frac{\\mu_1}{\\sigma_1}$ using $P_i$, $S_h$, and $\\Gamma_{ij}$. \n",
    "$$S/N_B \\equiv \\frac{\\mu_1}{ \\sigma_1} = \\Bigg[ 2 \\sum_f \\sum_{ij} \\frac{\\Gamma_{ij}^2 S_h^2}{P_iP_j + S_h[P_i + P_j] + S_h^2[1+\\Gamma_{ij}^2]}   \\Bigg]^{1/2} \\quad\\quad\\quad(\\mathrm{A}19)$$\n",
    "We can use this to check that our intermediate variables are all consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_B = det.SNR_bg_B(noise, Gamma, Sh_bg)\n",
    "SNR_1 = mu_1B/sigma_1B\n",
    "print(SNR_B.shape, holo.utils.stats(SNR_B))\n",
    "print(SNR_1.shape, holo.utils.stats(SNR_1))\n",
    "plt.plot(SNR_B, SNR_1) # should be equal\n",
    "plt.xlabel('$\\mathrm{S/N_B}(\\Gamma, S_h, P)$')\n",
    "plt.ylabel('$\\mathrm{S/N_B} = \\mu_1/\\sigma_1$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hasasia.sensitivity.GWBSensitivityCurve.SNR(Sh) comparison\n",
    "Hasasia.sensitivity.SNR(Sh) uses $$S_h = \\frac{3H_0^2}{2\\pi^2} \\frac{\\Omega_\\mathrm{gw}(f)}{f^3}$$ in units of strain^2/Hz, where $\\Omega_{gw}=\\frac{2\\pi^2}{3\\;H_0^2}f^3\\;S_I$ \n",
    "This uses a generic power law GWB calculated by hasasia in the $\\Omega_{gw}$ calculation. \n",
    "\n",
    "Or we can calculate S_h for our GWBs, based on Hazboun et al. 2019 Eq. (56) $$h_c(f) \\equiv \\sqrt{f S_h(f)}$$\n",
    "rewriting this as\n",
    "$$S_h(f) = h_c(f)^2/f$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sh_heff = det._Sh_hasasia_noise_bg(scGWB)\n",
    "Sh_hmod = det._Sh_hasasia_modeled_bg(fobs, hc_bg)\n",
    "print('Sh_heff at each frequency\\n', Sh_heff)\n",
    "print('Sh_hmod at each frequency, averaged over realizations\\n', np.mean(Sh_hmod, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fobs*YR, Sh_heff, label='hasasia $S_h(\\Omega_{gw})$ noise plaw', color=\"tab:blue\")\n",
    "plt.plot(fobs*YR, np.mean(Sh_hmod, axis=1), label='hasasia $S_h(h_c)$ modeled hc', color='tab:green')\n",
    "plt.yscale('log')\n",
    "plt.ylim(10e-28, 10e-11)\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency $f_\\mathrm{obs}$ (1/YR)')\n",
    "plt.ylabel('Power Spectral Density $S_h$ (Hz)$^{-1}$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look reasonably close for most frequencies, but the generic calculation has one very high value in th 10th frequency bin. Maybe this isn't actually the background calculation, but a sensitivity to the background calculation (and we have very low sensitivity at that one place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_hgen = det.SNR_hasasia_noise_bg(scGWB)\n",
    "SNR_hmod = det.SNR_hasasia_modeled_bg(scGWB, hc_bg)\n",
    "\n",
    "print('SNR_B of each realization\\n', SNR_B)\n",
    "print('SNR_hmod of each realization\\n', SNR_hmod) \n",
    "print('SNR_hgen\\n', SNR_hgen) # why is this the exact same as when I calculated it with a different scGWB?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = np.arange(len(SNR_B))\n",
    "plt.plot(reals, SNR_B, marker='o', label='SNR_B', color='tab:pink')\n",
    "plt.plot(reals, SNR_hmod, marker='*', label='hasasia, modeled hc', color='tab:green')\n",
    "plt.axhline(SNR_hgen, label='hasasia, noise', color='tab:blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Realization')\n",
    "plt.ylabel('SNR($S_h$)')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = np.arange(len(SNR_B))\n",
    "plt.plot(reals, SNR_B/2, marker='o', label='SNR_B/2', color='tab:pink')\n",
    "plt.plot(reals, SNR_hmod, marker='*', label='hasasia, modeled hc', color='tab:green')\n",
    "plt.axhline(SNR_hgen, label='hasasia, noise', color='tab:blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Realization')\n",
    "plt.ylabel('SNR($S_h$)')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = np.arange(len(SNR_B))\n",
    "plt.plot(reals, SNR_B/SNR_hmod, marker='o', label='SNR_B/SNR_hasasia', color='tab:red')\n",
    "# plt.plot(reals, SNR_hmod, marker='*', label='hasasia, modeled hc', color='tab:green')\n",
    "# plt.axhline(SNR_hgen, label='hasasia, gen plaw hc', color='tab:blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Realization')\n",
    "plt.ylabel('Ratio SNR_B/SNR_hasasia')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hasasia SNR with a generic background and modeled background look similar. Using a modeled GWB gives slightly higher SNR's than the generic GWB. These both give ~2-3x higher SNRs than our calculation using the Rosado+2015 equations, but are of the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sh_bg averaged over realizations\\n', np.mean(Sh_bg,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
