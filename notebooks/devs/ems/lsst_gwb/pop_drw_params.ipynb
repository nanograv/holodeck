{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import kalepy as kale\n",
    "\n",
    "import holodeck as holo\n",
    "import holodeck.ems\n",
    "from holodeck.constants import MSOL, PC, YR, GYR, SPLC, EDDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get population parameters from 15yr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/Users/lzkelley/programs/nanograv/15yr_astro_data/phenom/ceffyl_chains/astroprior_hdall\"\n",
    "path_data = Path(path_data).resolve()\n",
    "print(path_data)\n",
    "assert path_data.is_dir()\n",
    "fname_pars = path_data.joinpath(\"pars.txt\")\n",
    "fname_chains = path_data.joinpath(\"chain_1.0.txt\")\n",
    "print(fname_pars)\n",
    "print(fname_chains)\n",
    "assert fname_chains.is_file() and fname_pars.is_file()\n",
    "\n",
    "chain_pars = np.loadtxt(fname_pars, dtype=str)\n",
    "chains = np.loadtxt(fname_chains)\n",
    "npars = len(chain_pars)\n",
    "\n",
    "# Get maximum likelihood parameters (estimate using KDE)\n",
    "mlpars = {}\n",
    "fig, axes = plt.subplots(figsize=[10, 1.5*npars], nrows=npars)\n",
    "plt.subplots_adjust(hspace=0.75)\n",
    "for ii, ax in enumerate(axes):\n",
    "    ax.set(xlabel=chain_pars[ii])\n",
    "    vals = chains[:, ii]\n",
    "    extr = holo.utils.minmax(vals)\n",
    "    xx, yy = kale.density(vals, reflect=extr)\n",
    "    kale.dist1d(chains[:, ii], ax=ax, density=True, carpet=1000)\n",
    "    idx = np.argmax(yy)\n",
    "    xmax = xx[idx]\n",
    "    ax.axvline(xmax, color='firebrick')\n",
    "    mlpars[chain_pars[ii]] = xmax\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Maximum Likelihood binary population parameters:\")\n",
    "for kk, vv in mlpars.items():\n",
    "    print(f\"\\t{kk:>20s}: {vv:+.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the appropriate Parameter Space (from 15yr astro analysis)\n",
    "pspace = holo.param_spaces.PS_Uniform_09B\n",
    "# Load SAM and hardening model for desired parameters\n",
    "sam, hard = pspace.model_for_params(mlpars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose range of orbital periods of interest\n",
    "tvals = [10.0, 0.1]   # yr\n",
    "NFBINS = 10\n",
    "print(f\"Considering orbital periods between {tvals} yrs, {NFBINS} bins\")\n",
    "# convert to frequencies\n",
    "fobs_orb_edges = 1 / np.array(tvals)   # 1/yr\n",
    "# construct bins \n",
    "fobs_orb_edges = np.logspace(*np.log10(fobs_orb_edges/YR), NFBINS+1)  # 1/sec\n",
    "fobs_orb_cents = holo.utils.midpoints(fobs_orb_edges)\n",
    "fobs = fobs_orb_cents\n",
    "\n",
    "# calculate (differential) number of binaries\n",
    "redz_final, diff_num = holo.sams.cyutils.dynamic_binary_number_at_fobs(\n",
    "    fobs_orb_cents, sam, hard, holo.cosmo\n",
    ")\n",
    "# integrate to find total number of binaries in each bin\n",
    "edges = [sam.mtot, sam.mrat, sam.redz, fobs_orb_edges]\n",
    "number = holo.sams.cyutils.integrate_differential_number_3dx1d(edges, diff_num)\n",
    "print(f\"Loaded {number.sum():.1e} binaries across frequency range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate DRW parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaker()\n",
    "fedd_num = 10\n",
    "# we dont care about orbital frequency for this, so ignore\n",
    "cents = [holo.utils.midpoints(ee, log=True) for ee in edges[:-1]]\n",
    "mesh = [mm.flatten() for mm in np.meshgrid(*cents, indexing='ij')]\n",
    "size = mesh[0].size\n",
    "shape = (size, fedd_num, 2)\n",
    "fedd = holo.utils.log_normal_base_10(0.1, 0.5, shape)\n",
    "fedd[fedd > 1.0] = 1.0/fedd[fedd > 1.0]\n",
    "fedd = fedd.reshape(-1, 2)\n",
    "mesh = [mm[:, np.newaxis] * np.ones(shape[:-1]) for mm in mesh]\n",
    "mt, mr, rz = [mm.flatten() for mm in mesh]\n",
    "m1, m2 = holo.utils.m1m2_from_mtmr(mt, mr)\n",
    "\n",
    "num = number.sum(axis=-1).flatten()\n",
    "num = num[:, np.newaxis] * np.ones(shape[:-1])\n",
    "num = num.flatten() / fedd_num\n",
    "\n",
    "scatter = False\n",
    "imag_1, taus_1, sfis_1 = holo.ems.drw.drw_params(m1, fedd[:, 0], scatter=scatter)\n",
    "imag_2, taus_2, sfis_2 = holo.ems.drw.drw_params(m2, fedd[:, 1], scatter=scatter)\n",
    "\n",
    "scatter = True\n",
    "imag_1_scatter, taus_1_scatter, sfis_1_scatter = holo.ems.drw.drw_params(m1, fedd[:, 0], scatter=scatter)\n",
    "imag_2_scatter, taus_2_scatter, sfis_2_scatter = holo.ems.drw.drw_params(m2, fedd[:, 1], scatter=scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./drw_params.hdf5\"\n",
    "fname = Path(fname).resolve()\n",
    "with h5py.File(fname, 'w') as out:\n",
    "    out.create_dataset(\"m1\", data=m1)\n",
    "    out.create_dataset(\"m2\", data=m2)\n",
    "    out.create_dataset(\"num\", data=num)\n",
    "    out.create_dataset(\"redz\", data=rz)\n",
    "    out.create_dataset(\"fedd1\", data=fedd[:, 0])\n",
    "    out.create_dataset(\"fedd2\", data=fedd[:, 1])\n",
    "\n",
    "    group = out.create_group(\"mean\")\n",
    "    group.create_dataset(\"imag1\", data=imag_1)\n",
    "    group.create_dataset(\"imag2\", data=imag_2)\n",
    "    group.create_dataset(\"taus1\", data=taus_1)\n",
    "    group.create_dataset(\"taus2\", data=taus_2)\n",
    "    group.create_dataset(\"sfis1\", data=sfis_1)\n",
    "    group.create_dataset(\"sfis2\", data=sfis_2)\n",
    "\n",
    "    group = out.create_group(\"scatter\")\n",
    "    group.create_dataset(\"imag1\", data=imag_1_scatter)\n",
    "    group.create_dataset(\"imag2\", data=imag_2_scatter)\n",
    "    group.create_dataset(\"taus1\", data=taus_1_scatter)\n",
    "    group.create_dataset(\"taus2\", data=taus_2_scatter)\n",
    "    group.create_dataset(\"sfis1\", data=sfis_1_scatter)\n",
    "    group.create_dataset(\"sfis2\", data=sfis_2_scatter)\n",
    "    \n",
    "print(f\"Saved to {fname}, size {holo.utils.get_file_size(fname)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
