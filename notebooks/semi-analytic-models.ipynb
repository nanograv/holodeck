{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# `holodeck` - Semi-Analytic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "For more information on the holodeck SAMs, see the [holodeck getting started guide](https://holodeck-gw.readthedocs.io/en/main/getting_started/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import holodeck as holo\n",
    "from holodeck import sams\n",
    "from holodeck import utils, plot\n",
    "from holodeck.constants import MSOL, YR\n",
    "\n",
    "holo.log.setLevel(holo.log.ERROR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Construct a Semi-Analytic Model (SAM) using all of the default components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the shape of the SAM grid to be a small number (e.g. `30`), so that this example runs quickly\n",
    "# (although with low accuracy).\n",
    "sam = sams.Semi_Analytic_Model(shape=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Choose the edges of the frequency bins at which to calculate the GWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_DUR = 10.0 * YR    # duration of PTA observations in [sec], which determines the Fourier frequency basis\n",
    "NUM_FREQS = 20         # number of frequency bins\n",
    "fobs, fobs_edges = utils.pta_freqs(dur=OBS_DUR, num=NUM_FREQS)\n",
    "print(f\"Number of frequency bins: {fobs.size}\")\n",
    "print(f\"  between [{fobs[0]*YR:.2f}, {fobs[-1]*YR:.2f}] 1/yr\")\n",
    "print(f\"          [{fobs[0]*1e9:.2f}, {fobs[-1]*1e9:.2f}] nHz\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Calculate GWB from this SAM.  \n",
    "We need to specify the edges of the frequency bins that are being observed (`fobs_edges`).  \n",
    "We also ask for many different 'realizations' of the universe to get a distribution of expected amplitudes.  \n",
    "And finally we will obtain a handful of the 'loudest' binaries in each frequency bin, ('single sources'),  in addition to the sum of the characteristic strains of all remaining binaries (the background).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_REALS = 100    # Number of 'realizations' to generate\n",
    "NUM_LOUDEST = 2   # Number of 'loudest' binaries to generate in each frequency bin\n",
    "hc_ss, hc_bg = sam.gwb(fobs_edges, realize=NUM_REALS, loudest=NUM_LOUDEST)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Plot GWB over multiple realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(fobs*1e9, hc_bg, lw=0.5, alpha=0.5);\n",
    "plt.gca().set(ylabel='Characteristic Strain ($h_c$)', xlabel='GW Frequency [nHz]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Slightly fancier plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(xlabel='GW Frequency $f_\\mathrm{obs}$ [1/yr]', ylabel='Characteristic Strain $h_c$')\n",
    "\n",
    "# `fobs` are bin centers in CGS units, convert to [1/yr]\n",
    "xx = fobs * YR\n",
    "\n",
    "# Get the median over all the realizations\n",
    "med = np.median(hc_bg, axis=-1)\n",
    "\n",
    "# plot a reference, pure power-law  strain spectrum:   h_c(f) = A * (f * yr) ^ -2/3\n",
    "yy = med[0] * np.power(xx/xx[0], -2.0/3.0)\n",
    "ax.plot(xx, yy, 'k--', alpha=0.25, lw=2.0)\n",
    "\n",
    "# Plot the median GWB spectrum\n",
    "ax.plot(xx, med, 'k-', alpha=0.5)\n",
    "\n",
    "# Combine the `loudest` binaries in all realizations, to get distributions of their strains\n",
    "singles = hc_ss.reshape((hc_ss.shape[0], -1))\n",
    "\n",
    "# Plot distributions of GWB and Continuous Wave (CW) strains over all realizations\n",
    "# contours at 50% and 98% confidence intervals\n",
    "for pp in [50, 98]:\n",
    "    percs = pp / 2\n",
    "    percs = [50 - percs, 50 + percs]\n",
    "    h1 = ax.fill_between(xx, *np.percentile(hc_bg, percs, axis=-1), alpha=0.25, color='#7100d4')\n",
    "    h2 = ax.fill_between(xx, *np.percentile(singles, percs, axis=-1), alpha=0.25, color='orangered')\n",
    "\n",
    "ax.legend([h1, h2], ['GWB', 'CWs'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Constructing a SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "SAMs are built from simple analytic models to derive the number-density of MBH binaries.\n",
    "To do this, we start with a **galaxy stellar-mass function (GSMF; $\\psi$)** which determines the number of \n",
    "galaxies as a function of stellar mass.  We then multiply by a **galaxy merger rate (GMR; $R$)** to get\n",
    "the rate of galaxy-galaxy mergers:\n",
    "\n",
    "$$\\frac{\\partial^3 n_{\\star\\star}(M_\\star, q_\\star, z)}{\\partial \\log_{10}(M_\\star) \\, \\partial q_\\star \\, \\partial z} = \\psi(m_{1,\\star}) \\cdot R(M_\\star, q_\\star, z).$$\n",
    "\n",
    "Here, the total stellar-mass of both galaxies is $M_\\star \\equiv m_{1,\\star} + m_{2,\\star}$, and the stellar mass ratio is $q_\\star \\equiv m_{2,\\star} / m_{1,\\star}.$\n",
    "\n",
    "To convert from galaxy-galaxy to MBHâ€“MBH mergers, we use a relationship between host-galaxy and MBHs, typically in the form of an **M-Mbulge (MMB)** relationship: the MBH mass as a function of galaxy stellar-bulge mass, $M = M_{BH}(M_\\star)$, so that we can write:\n",
    "\n",
    "$$\\frac{\\partial^3 n(M, q, z)}{\\partial \\log_{10}(M) \\, \\partial q \\, \\partial z}  = \\psi(m_{1,\\star}) \\cdot R(M_\\star, q_\\star, z) \\cdot \\frac{\\partial M_\\star}{\\partial M} \\frac{\\partial q_\\star}{\\partial q}.$$\n",
    "\n",
    "The GMR is very hard to determine observationally, so it's common to approximate it as the ratio of a **galaxy pair-fraction (GPF; $P$)**, and a **galaxy merger time (GMT; $T$)**, i.e. $$R(M_\\star, q_\\star, z) \\approx \\frac{P(m_{1,\\star}, q_\\star, z)}{T(M_\\star, q_\\star, z)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The SAMs are initialized over a 3-dimensional parameter space of total MBH mass ($M = m_1 + m_2$), MBH mass ratio ($q = m_2 / m_1 \\leq 1$), and redshift ($z$).  The `holodeck` code typically refers to the number of bins in each of these dimensions as `M`, `Q`, and `Z`; for example, the shape of the number-density of galaxy mergers will be `(M, Q, Z)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the size of the SAM grid, with shape (M, Q, Z) for a grid of (total-mass, mass-ratio, redshift).\n",
    "# We'll use a small grid so that calculations are fast (but not very accurate).\n",
    "SAM_SHAPE = (30, 31, 32)\n",
    "\n",
    "\n",
    "# ---- Build SAM using Galaxy Merger-Rate:\n",
    "\n",
    "# gsmf = holo.sams.GSMF_Schechter()               # Galaxy Stellar-Mass Function (GSMF)\n",
    "# gmr = holo.sams.GMR_Illustris()                 # Galaxy Merger Rate           (GMR)\n",
    "# mmbulge = holo.host_relations.MMBulge_MM2013()       # M-MBulge Relation            (MMB)\n",
    "\n",
    "# sam = holo.sams.Semi_Analytic_Model(gsmf=gsmf, gmr=gmr, mmbulge=mmbulge, shape=SAM_SHAPE)\n",
    "\n",
    "\n",
    "# ---- Build SAM using Galaxy Pair-Fraction and Galaxy Merger-Time:\n",
    "\n",
    "gsmf = holo.sams.GSMF_Schechter()               # Galaxy Stellar-Mass Function (GSMF)\n",
    "gpf = holo.sams.GPF_Power_Law()                 # Galaxy Pair Fraction         (GPF)\n",
    "gmt = holo.sams.GMT_Power_Law()                 # Galaxy Merger Time           (GMT)\n",
    "mmbulge = holo.host_relations.MMBulge_MM2013()       # M-MBulge Relation            (MMB)\n",
    "\n",
    "sam = holo.sams.Semi_Analytic_Model(gsmf=gsmf, gpf=gpf, gmt=gmt, mmbulge=mmbulge, shape=SAM_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### number density and the SAM grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The formation rate of MBH-MBH 'binaries' is calculated in `Semi_Analytic_Model.static_binary_density`, evaluated at the edges of the grid so that it's shape is the number of bins in each dimension, plus one, i.e. `(M+1, Q+1, Z+1)`.  `static_binary_density` is implemented as a `@property` so that the first time the value is accessed it is calculated and cached, and then returned immediately on subsequent calls. \n",
    "\n",
    "NOTE: at this point, these are not necessarily gravitationally-bound MBH 'binaries', but instead pairs of two MBHs coming together in a galaxy-galaxy merger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Calculated `static_binary_density` for the first time... (you can probably ignore all of the messages, including non-fatal 'ERROR's.)\")\n",
    "nden = sam.static_binary_density  # this will trigger the variable to be calculated and cached.\n",
    "print(f\"Shape of number density: {nden.shape}\")\n",
    "\n",
    "# `sam.edges` returns a tuple with each of the grid-edges\n",
    "print(f\"SAM `mtot` edges: [{sam.mtot[0]/MSOL:.1e}, {sam.mtot[-1]/MSOL:.1e}] with {sam.mtot.size} edges.\")\n",
    "print(f\"SAM `mrat` edges: [{sam.mrat[0]:.1e}, {sam.mrat[-1]:.1e}] with {sam.mrat.size} edges.\")\n",
    "print(f\"SAM `redz` edges: [{sam.redz[0]:.1e}, {sam.redz[-1]:.1e}] with {sam.redz.size} edges.\")\n",
    "# The shape of the edges is stored as `sam.shape`\n",
    "print(f\"SAM `shape` (variable): {sam.shape}\")\n",
    "# All three of the grid edges are returned as a tuple when called `sam.edges`\n",
    "print(f\"SAM shape (from `edges`): {[ee.size for ee in sam.edges]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the number-density of binaries in `(M, Q)` space at a particular redshift slice\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "redz_indx = 15   # randomly chosen redshift index number\n",
    "\n",
    "# because `static_binary_density` was already accessed above, this call does NOT recalculate\n",
    "# the density, it just returns the cached values\n",
    "nden = sam.static_binary_density[:, :, redz_indx]\n",
    "print(f\"Shape of number density slice at fixed redz: {nden.shape}\")\n",
    "\n",
    "fig, ax = holo.plot.figax(xlabel='Total Mass $[M_\\odot]$', ylabel='Mass Ratio')\n",
    "# we transpose the number-density because matplotlib thinks in terms of images instead of arrays\n",
    "# we're manually setting the lower-limit for the colorbar because some values are often ~0\n",
    "pcm = ax.pcolormesh(sam.mtot / MSOL, sam.mrat, np.log10(nden).T, vmin=-10)\n",
    "\n",
    "# Note that this is a distribution function (the values are ``d^3n / dlog10(M) dq dz``),\n",
    "# of a volumentric number density (n = Number/Volume) and\n",
    "# a rate (per unit redshfit: 1/dz).  So the units are a bit complicated:\n",
    "label_units = (\n",
    "    r'$\\log_{10}\\left['\n",
    "    r'(\\partial^3 n / \\partial \\log_{10} M \\, \\partial q \\, \\partial z)'\n",
    "    r'/'\n",
    "    r'(\\mathrm{Mpc}^{-3} \\, \\mathrm{dex}^{-1})'\n",
    "    r'\\right]$'\n",
    ")\n",
    "plt.colorbar(pcm, ax=ax, label=label_units)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### total number of binaries in a universe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Above, we calculated the volumetric number-density rate of binary mergers.  Here, we calculate the total number of binaries in a simulated universe at particular GW frequencies of interest.  The SAM models currently assume circular binary orbits, so that the GW frequency is exactly twice the orbital frequency.\n",
    "\n",
    "To calculate the number of binaries over frequency, we basically just use the chain rule (but note that this glances over a lot of subtle physics):\n",
    "\n",
    "$$\\frac{\\partial^3 N(M, q, z, f)}{\\partial \\log_{10}\\! M \\, \\partial q \\, \\partial z \\, \\partial \\ln\\! f} = \n",
    "\\frac{\\partial^3 n(M, q, z)}{\\partial \\log_{10}\\! M \\, \\partial q \\, \\partial z}\n",
    "\\left( \\frac{\\partial V_c}{\\partial z} \\right) \n",
    "\\left( \\frac{\\partial z}{\\partial t} \\right)\n",
    "\\left( \\frac{\\partial t}{\\partial \\ln\\! f} \\right).$$\n",
    "\n",
    "The left-hand side is what we want.  The right-hand side has four terms.  The first is the `static_number_density` that we calculated previously.  The second is the differential comoving-volume of the universe as a function of redshift, and the third converts between the rate of time- and redshift- evolution of the universe.  The important term is the last one, called the **residence time** or **hardening time** of binaries:\n",
    "\n",
    "$$\\frac{\\partial t}{\\partial \\ln\\! f} = \\frac{f}{\\left( \\partial f / \\partial t \\right)} \\equiv \\tau_f.$$\n",
    "\n",
    "The way to understand this term, is that the longer binaries spend in a given frequency interval, the more likely binaries are to be found at those frequencies, and thus in a random snapshot of the universe, the more binaries will be found there.  This term requires some model for **binary evolution** (often referred to as **binary 'hardening'**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose frequency bins over which to calculate binaries.\n",
    "# Construct frequency-bin edges\n",
    "fobs_gw_edges = np.logspace(-1, 2, 31) / YR\n",
    "# Calculate the mid-points of each pair of edges to use as bin-centers\n",
    "fobs_gw_cents = holo.utils.midpoints(fobs_gw_edges, log=True)\n",
    "print(f\"{fobs_gw_cents.size} frequency bins between [{fobs_gw_edges[0]*YR:.1e}, {fobs_gw_edges[-1]*YR:.1e} 1/yr]\")\n",
    "print(f\"{fobs_gw_cents.size} frequency bins between [{fobs_gw_edges[0]*1e9:.1e}, {fobs_gw_edges[-1]*1e9:.1e} nHz]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "For each point in the 3-dimensional SAM grid, we will be calculating the number of binaries at each frequency.  So the returned values will be 4-dimensional with an additional axis with `F` frequency bins added: `(M, Q, Z, F)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**GW-Only Binary Evolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an instance of the GW-Hardening class `Hard_GW`\n",
    "hard_gw = holo.hardening.Hard_GW()\n",
    "\n",
    "# Calculate the differential number of binaries, ``dN/[dlog10M dq qz dlnf]``\n",
    "# convert from GW frequencies to orbital frequencies (still observer-frame)\n",
    "fobs_orb_edges = fobs_gw_edges / 2.0\n",
    "fobs_orb_cents = fobs_gw_cents / 2.0\n",
    "# `diff_num` is a 4D array with shape (M+1, Q+1, Z+1, F)\n",
    "# these values are evaluated at bin edges for total-mass, mass-ratio, redshift, but freq bin-centers\n",
    "_edges, diff_num_gw, redz_final = sam.dynamic_binary_number_at_fobs(hard_gw, fobs_orb_cents, use_cython=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrat_indx = -1   # choose mass-ratio index near unity\n",
    "redz_indx = 15   # choose redshift index\n",
    "\n",
    "# choose a few different frequency indices\n",
    "fobs_indx = [0, -1]\n",
    "\n",
    "# The 'number' of binaries is still a differential number\n",
    "units = 'Number [$d^4 N/ d\\log_{10}\\! M \\, dq \\, dz \\, d\\ln \\! f$]'\n",
    "\n",
    "fig, ax = holo.plot.figax(xlabel='Total Mass [$M_\\odot$]', ylabel=units, ylim=[1e-2, 1e12])\n",
    "for fidx in fobs_indx:\n",
    "    fo = fobs_gw_cents[fidx]\n",
    "    num = diff_num_gw[:, mrat_indx, redz_indx, fidx]\n",
    "    ax.plot(sam.mtot/MSOL, num, label=f'{fo*1e9:.1f} nHz')\n",
    "\n",
    "ax.legend(title='GW frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Convert from differential number of binaries to actual number of binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate the differential number over each bin to get the total number ``N`` per bin\n",
    "edges = [sam.mtot, sam.mrat, sam.redz, fobs_orb_edges]\n",
    "# `number` is now a 4D array with shape `(M, Q, Z, F)`\n",
    "# all 4 axes are now 'bin centers', but note that the Frequency dimension did not change in shape\n",
    "number_gw = holo.sams.sam_cyutils.integrate_differential_number_3dx1d(edges, diff_num_gw)\n",
    "\n",
    "# total number of binaries in the universe\n",
    "print(f\"Total number of modeled binaries: {number_gw.sum():.1e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "nden.shape, diff_num_gw.shape, number_gw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Calculate the total number of binaries in certain ranges of parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose parameter bounds\n",
    "mtot_extr = [1e7*MSOL, 1e11*MSOL]\n",
    "mrat_extr = [0.1, np.inf]\n",
    "redz_extr = [-np.inf, +np.inf]\n",
    "fobs_gw_extr = [-np.inf, +np.inf]\n",
    "\n",
    "# make some lists\n",
    "extrema = [mtot_extr, mrat_extr, redz_extr, fobs_gw_extr]\n",
    "# we need to compare to values at bin-centers, instead of bin-edges\n",
    "centers = [holo.utils.midpoints(ee, log=True) for ee in edges]\n",
    "select = [(extr[0] < cent) & (cent < extr[1]) for extr, cent in zip(extrema, centers)]\n",
    "num = number_gw.copy()\n",
    "# slice along each dimension\n",
    "for ii in range(num.ndim):\n",
    "    num = np.moveaxis(num, ii, 0)\n",
    "    num = num[select[ii]]\n",
    "    num = np.moveaxis(num, 0, ii)\n",
    "\n",
    "print(f\"Number of binaries = {num.sum():.2e}  |  with parameters: \")\n",
    "print(f\"\\t{mtot_extr[0]/MSOL:.1e} < M/Msol < {mtot_extr[1]/MSOL:.1e}\")\n",
    "print(f\"\\t{mrat_extr[0]:.1e} < q < {mrat_extr[1]:.1e}\")\n",
    "print(f\"\\t{redz_extr[0]:.1e} < z < {redz_extr[1]:.1e}\")\n",
    "print(f\"\\t{fobs_gw_extr[0]:.1e} < f < {fobs_gw_extr[1]:.1e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Self-Consistent Binary Evolution (Phenomenological Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a total binary lifetime (from formation to coalescence)\n",
    "lifetime = 0.1e9 * YR\n",
    "# construct an instance of the 'Phenomenological' Hardening class `Fixed_Time_2PL_SAM`\n",
    "hard_ph = holo.hardening.Fixed_Time_2PL_SAM(sam, lifetime)\n",
    "\n",
    "# Calculate the differential number of binaries, ``dN/[dlog10M dq qz dlnf]``\n",
    "_edges, diff_num_ph, redz_final = sam.dynamic_binary_number_at_fobs(hard_ph, fobs_orb_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrat_indx = -1   # choose mass-ratio index near unity\n",
    "redz_indx = 20   # choose redshift index\n",
    "\n",
    "# choose a few different frequency indices\n",
    "fobs_indx = [0, -1]\n",
    "\n",
    "# The 'number' of binaries is still a differential number\n",
    "units = 'Number [$d^4 N/ d\\log_{10}\\! M \\, dq \\, dz \\, d\\ln \\! f$]'\n",
    "\n",
    "fig, ax = holo.plot.figax(xlabel='Total Mass [$M_\\odot$]', ylabel=units, ylim=[1e-2, 1e12])\n",
    "for fidx in fobs_indx:\n",
    "    fo = fobs_gw_cents[fidx]\n",
    "\n",
    "    # plot GW evolution\n",
    "    num = diff_num_gw[:, mrat_indx, redz_indx, fidx]\n",
    "    h1, = ax.plot(sam.mtot/MSOL, num, label=f'{fo*1e9:.1f} nHz')\n",
    "\n",
    "    # plot phenomenological evolution\n",
    "    num = diff_num_ph[:, mrat_indx, redz_indx, fidx]\n",
    "    h2, = ax.plot(sam.mtot/MSOL, num, ls='--', color=h1.get_color())\n",
    "\n",
    "leg = ax.legend(title='GW frequency', loc='upper right')\n",
    "ax.legend([h1, h2], ['GW', 'Phenom'], title='hardening', loc='lower right')\n",
    "ax.add_artist(leg)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Gravitational Waves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Compare GWB and CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_REALS = 100    # Number of 'realizations' to generate\n",
    "NUM_LOUDEST = 6   # Number of 'loudest' binaries to generate in each frequency bin\n",
    "\n",
    "PTA_DUR = 40.0 * YR\n",
    "NUM_FREQS = 50\n",
    "\n",
    "fobs_gw_cents, fobs_gw_edges = holo.utils.pta_freqs(PTA_DUR, NUM_FREQS)\n",
    "\n",
    "# GW evolution\n",
    "hc_ss_gw, hc_bg_gw = sam.gwb(fobs_gw_edges, hard=hard_gw, realize=NUM_REALS, loudest=NUM_LOUDEST)\n",
    "# Phenomenological evolution\n",
    "hc_ss_ph, hc_bg_ph = sam.gwb(fobs_gw_edges, hard=hard_ph, realize=NUM_REALS, loudest=NUM_LOUDEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "xx = fobs_gw_cents * 1e9\n",
    "for ss, bg, lab in zip([hc_ss_gw, hc_ss_ph], [hc_bg_gw, hc_bg_ph], ['GW-only', 'phenom']):\n",
    "    yy = np.median(bg, axis=1)\n",
    "    h1, = ax.loglog(xx, yy, label=lab)\n",
    "\n",
    "    # combine 'loudest' binaries with realizations, and take median over both\n",
    "    ss = ss.reshape(ss.shape[0], -1)\n",
    "    yy = np.median(ss, axis=1)\n",
    "    h2, = ax.loglog(xx, yy, ls='--', color=h1.get_color())\n",
    "\n",
    "leg = ax.legend(loc='upper right')\n",
    "ax.legend([h1, h2], ['GWB', 'CW'], loc='lower left')\n",
    "ax.add_artist(leg)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Calculate the distribution of GWB Amplitudes at 1/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose our target GW frequency\n",
    "fobs = 1.0/YR\n",
    "# Choose an appropriate bin width\n",
    "fobs_width = fobs/16.0\n",
    "fobs_edges = np.array([fobs - 0.5*fobs_width, fobs + 0.5*fobs_width])\n",
    "hc_ss, hc_bg = sam.gwb(fobs_edges, hard=hard_gw, realize=300, loudest=1)\n",
    "# Calculate the idealized GWB amplitude from this population\n",
    "gwb_ref = sam.gwb_ideal(fobs)\n",
    "\n",
    "amp_bg = hc_bg.flatten()\n",
    "# combine the single-sources and background sources into total amplitude\n",
    "amp_tot = np.sum(hc_ss**2, axis=-1) + hc_bg**2\n",
    "amp_tot = np.sqrt(amp_tot).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8, 4])\n",
    "ax.set(xlabel=r'$\\log_{10}(A_\\mathrm{yr})$', ylabel='Probability Density')\n",
    "ax.grid(alpha=0.2)\n",
    "\n",
    "try:\n",
    "    # use `kalepy` do draw the 1D distribution\n",
    "    import kalepy as kale\n",
    "    h1 = kale.dist1d(np.log10(amp_tot), density=True, confidence=True)\n",
    "    h2 = kale.dist1d(np.log10(amp_bg), density=True, confidence=False)\n",
    "except ImportError:\n",
    "    kw = dict(bins=20, density=True, histtype='step')\n",
    "    *_, h1 = ax.hist(np.log10(amp_tot), **kw)\n",
    "    *_, h2 = ax.hist(np.log10(amp_bg), **kw)\n",
    "    h1 = h1[0]\n",
    "    h2 = h2[0]\n",
    "\n",
    "h3 = ax.axvline(np.log10(gwb_ref), ls='--', color='k')\n",
    "ax.legend([h1, h2, h3], ['Total', 'BG only', 'idealized'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Plot GWB Amplitude Distribution vs. M-MBulge parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Calculate GWB amplitudes at $f = 1/yr$ over a grid of M-Mbulge parameters, specifically the amplitude and power-law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose parameters to explore\n",
    "NREALS = 10     # number of realizations at each parameter combination\n",
    "alpha_list = [1.0, 1.5]     # M-Mbulge power-law index\n",
    "norm_list = [3e8, 3e9]\n",
    "# norm_list = np.logspace(8, 9.5, 4)     # M-Mbulge normalization, units of [Msol]\n",
    "\n",
    "dist_mmb = np.zeros((len(alpha_list), len(norm_list), NREALS))\n",
    "\n",
    "# Iterate over a grid of both paremeters\n",
    "for aa, alpha in enumerate(tqdm.tqdm(alpha_list)):\n",
    "    for nn, norm in enumerate(tqdm.tqdm(norm_list, leave=False)):\n",
    "        # Create the M-Mbulge relationship for these parameters\n",
    "        mmbulge = holo.host_relations.MMBulge_Standard(mamp=norm*MSOL, mplaw=alpha)\n",
    "        # Build a new sam\n",
    "        sam = holo.sams.Semi_Analytic_Model(gsmf=gsmf, gpf=gpf, gmt=gmt, mmbulge=mmbulge, shape=20)\n",
    "        # Calculate the distribution of GWB amplitudes\n",
    "        cw, dist_mmb[aa, nn, :] = sam.gwb(fobs_edges, realize=NREALS, loudest=0)\n",
    "        if nn == 0:\n",
    "            print(f\"{aa=} {alpha=} {np.median(dist_mmb[aa, nn, :]):.4e}\")\n",
    "        # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Plot the interquartile ranges for each power-law, as a function of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax.set(xscale='log', xlabel='M-MBulge Mass Normalization', yscale='log', ylabel=r'GWB Amplitude $A_\\mathrm{yr}$')\n",
    "ax.grid(alpha=0.2)\n",
    "\n",
    "for aa, dd in zip(alpha_list, dist_mmb):\n",
    "    med = np.median(dd, axis=-1)\n",
    "    cc, = ax.plot(norm_list, med, label=aa)\n",
    "    cc = cc.get_color()\n",
    "    ax.fill_between(norm_list, *np.percentile(dd, [25, 75], axis=-1), color=cc, alpha=0.15)\n",
    "\n",
    "plt.legend(title='M-MBulge Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sam = holo.sams.Semi_Analytic_Model(shape=(10, 11, 12))\n",
    "print(f\"{sam.shape=}\")\n",
    "hard_gw = holo.hardening.Hard_GW()\n",
    "\n",
    "nden = sam.static_binary_density\n",
    "\n",
    "PTA_DUR = 20.0 * YR\n",
    "NUM_FREQS = 9\n",
    "fobs_gw_cents, fobs_gw_edges = holo.utils.pta_freqs(PTA_DUR, NUM_FREQS)\n",
    "fobs_orb_cents = fobs_gw_cents / 2.0\n",
    "fobs_orb_edges = fobs_gw_edges / 2.0\n",
    "\n",
    "grid_py, dnum_py, redz_final_py = sam.dynamic_binary_number_at_fobs(hard_gw, fobs_orb_cents, use_cython=False)\n",
    "grid_cy, dnum_cy, redz_final_cy = sam.dynamic_binary_number_at_fobs(hard_gw, fobs_orb_cents, use_cython=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"grid\")\n",
    "for ii in range(4):\n",
    "    print(ii, np.allclose(grid_py[ii], grid_cy[ii]))\n",
    "\n",
    "print(\"redz\", np.allclose(redz_final_py, redz_final_cy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_redz = (redz_final_py - redz_final_cy)\n",
    "# idx_redz = (redz_final_cy > 0.0)\n",
    "idx_redz = (redz_final_py > 0.0)\n",
    "diff_redz[idx_redz] = diff_redz[idx_redz] / redz_final_cy[idx_redz]\n",
    "\n",
    "print(f\"{utils.frac_str(idx_redz)=}\")\n",
    "print(f\"{utils.stats(diff_redz[~idx_redz])=}\")\n",
    "print(f\"{utils.stats(diff_redz[idx_redz])=}\")\n",
    "print(f\"{utils.stats(diff_redz)=}\")\n",
    "\n",
    "print()\n",
    "\n",
    "diff_dnum = (dnum_py - dnum_cy)\n",
    "idx_dnum = (dnum_cy > 0.0)\n",
    "diff_dnum[idx_dnum] = diff_dnum[idx_dnum] / dnum_cy[idx_dnum]\n",
    "\n",
    "print(f\"{utils.frac_str(idx_dnum)=}\")\n",
    "print(f\"{utils.stats(diff_dnum[~idx_dnum])=}\")\n",
    "print(f\"{utils.stats(diff_dnum[idx_dnum])=}\")\n",
    "print(f\"{utils.stats(diff_dnum)=}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"{utils.frac_str(idx_redz == idx_dnum)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Different Redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bads_redz = ~np.isclose(redz_final_py, redz_final_cy)\n",
    "print(f\"{utils.frac_str(bads_redz)=}\")\n",
    "\n",
    "print(redz_final_py[bads_redz][:10])\n",
    "print(redz_final_cy[bads_redz][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(bads_redz)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEL = 0\n",
    "vals = np.meshgrid(*grid_py, indexing='ij')[SEL][bads_redz]\n",
    "np.unique(vals/MSOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## Different Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bads_dnum = ~np.isclose(dnum_py, dnum_cy)\n",
    "print(f\"{utils.frac_str(bads_dnum)=}\")\n",
    "\n",
    "print(dnum_py[bads_dnum][:10])\n",
    "print(dnum_cy[bads_dnum][:10])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
